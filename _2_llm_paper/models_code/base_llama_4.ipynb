{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fca6db89",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "603ac822",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import re\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig, TrainingArguments, EarlyStoppingCallback\n",
    "from peft import LoraConfig, get_peft_model, prepare_model_for_kbit_training\n",
    "from sklearn.model_selection import train_test_split\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "from huggingface_hub import login\n",
    "from trl import SFTTrainer\n",
    "from datasets import Dataset\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_recall_fscore_support, classification_report\n",
    "from tqdm import tqdm\n",
    "import import_ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b62ede45",
   "metadata": {},
   "source": [
    "# Prompt Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a05f2fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_prompt(row):\n",
    "    title = row.get('Title', '')\n",
    "    text = row.get('Full Text', '')\n",
    "    currencies = row.get('mentioned_currencies')\n",
    "\n",
    "    target_currencies = ''\n",
    "    for c in currencies:\n",
    "        target_currencies += f'{c}_past: \"appreciation, depreciation, or unchanged\",\\n'\n",
    "        target_currencies += f'{c}_future: \"appreciation, depreciation, or unchanged\",\\n'\n",
    "    target_currencies = target_currencies.strip().rstrip(\",\") # Remove last comma\n",
    "\n",
    "    # Same structure as per paper\n",
    "    return (\n",
    "        f\"Title: {title}\\n\"\n",
    "        f\"Text: {text}\\n\\n\"\n",
    "        \"Instructions:\\n\"\n",
    "        \"Objective: For each mentioned currency, answer the following questions:\\n\"\n",
    "        \"- What has been the current/past movement of the currency (appreciation, depreciation, or unchanged)?\\n\"\n",
    "        \"- What is the future expectation for the currency (appreciation, depreciation, or unchanged)?\\n\\n\"\n",
    "        \"You must answer these two questions for each of the following currencies mentioned in the article:\\n\"\n",
    "        f\"{target_currencies}\\n\\n\"\n",
    "        \"Output Format:\\n\"\n",
    "        \"- Important: Provide your answer in separate rows for each currency as shown above.\\n\"\n",
    "        \"- Do not combine multiple currencies in the same row.\\n\"\n",
    "        '- Each currency should have its own line with \"_past\" or \"_future\" specified.\\n\\n'\n",
    "        \"Example:\\n\"\n",
    "        '- If the article states, \"The EUR is expected to appreciate,\" the output should be:\\n'\n",
    "        '    EUR_past: \"unchanged\",\\n'\n",
    "        '    EUR_future: \"appreciation\"\\n'\n",
    "        '- If the article states, \"EUR/USD depreciated last week,\" the output should be:\\n'\n",
    "        '    EUR_past: \"depreciation\",\\n'\n",
    "        '    USD_past: \"appreciation\"\\n'\n",
    "        '- If only future movements are mentioned for a currency, the past movement should be labelled as \"unchanged\" and vice versa.\\n\\n'\n",
    "        \"Currency Pair Interpretation:\\n\"\n",
    "        \"- If currencies are discussed in pairs, interpret as follows:\\n\"\n",
    "        '    - If \"EUR/USD appreciated,\" label EUR_past as \"appreciation\" and USD_past as \"depreciation\".\\n'\n",
    "        '    - If \"EUR/USD depreciated,\" label EUR_past as \"depreciation\" and USD_past as \"appreciation\".\\n\\n'\n",
    "        \"Synonyms:\\n\"\n",
    "        \"- Recognize the following synonyms for each currency:\\n\"\n",
    "        \"- **EUR**: EUR, Euro\\n\"\n",
    "        \"- **USD**: USD, Dollar, Dollars, US Dollar, US-Dollar, U.S. Dollar, US Dollars, US-Dollars, U.S. Dollars, Greenback\\n\"\n",
    "        \"- **JPY**: JPY, Yen, Japanese Yen\\n\"\n",
    "        \"- **GBP**: GBP, Pound, Pounds, Sterling, British Pound, British Pounds\\n\"\n",
    "        \"- **AUD**: AUD, Australian Dollar, Australian Dollars, Aussie\\n\"\n",
    "        \"- **CAD**: CAD, Canadian Dollar, Canadian Dollars\\n\"\n",
    "        \"- **CHF**: CHF, Swiss Franc, Swiss Francs, Swissie\\n\"\n",
    "        \"- **NZD**: NZD, New Zealand Dollar, New Zealand Dollars, Kiwi\\n\"\n",
    "        \"- **NOK**: NOK, Norwegian Krone, Norwegian Kroner\\n\"\n",
    "        \"- **SEK**: SEK, Swedish Krona, Swedish Kronor\\n\\n\"\n",
    "        \"Answer below in the given format:\\n\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdd0ccea",
   "metadata": {},
   "source": [
    "# Llama LLM Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8967f9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup(model_id):\n",
    "\n",
    "    load_dotenv()\n",
    "    login(token=os.getenv(\"HF_TOKEN\"))\n",
    "    \n",
    "    # Setup Quantization\n",
    "    bnb_config = BitsAndBytesConfig(\n",
    "        load_in_4bit=True,\n",
    "        bnb_4bit_use_double_quant=True,\n",
    "        bnb_4bit_quant_type=\"nf4\",\n",
    "        bnb_4bit_compute_dtype=torch.bfloat16\n",
    "    )\n",
    "\n",
    "    # Load Tokenizer\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "\n",
    "    if tokenizer.pad_token is None:\n",
    "        # Check for Llama 3 specific reserved token first\n",
    "        if '<|reserved_special_token_0|>' in tokenizer.get_vocab():\n",
    "            tokenizer.pad_token = '<|reserved_special_token_0|>'\n",
    "            tokenizer.pad_token_id = tokenizer.convert_tokens_to_ids('<|reserved_special_token_0|>')\n",
    "            print(\"Set pad_token to Llama 3 reserved token (<|reserved_special_token_0|>)\")\n",
    "        else:\n",
    "            raise Exception(\"Can't find padding token\")\n",
    "\n",
    "    else:\n",
    "        print(f\"Padding token is already set to: {tokenizer.pad_token}\")\n",
    "    \n",
    "    \n",
    "    tokenizer.padding_side = \"left\"    # for inference\n",
    "\n",
    "    # Load model\n",
    "    model = AutoModelForCausalLM.from_pretrained(\n",
    "        model_id,\n",
    "        quantization_config=bnb_config,\n",
    "        device_map=\"auto\",\n",
    "        torch_dtype=torch.bfloat16\n",
    "    )\n",
    "\n",
    "    # Move model to GPU if available\n",
    "    if torch.cuda.is_available():\n",
    "        device = torch.device(\"cuda:0\")\n",
    "        model = model.to(device)\n",
    "        print(f\"Model explicitly loaded onto: {device}\")\n",
    "    else:\n",
    "        device = torch.device(\"cpu\")\n",
    "        model = model.to(device)\n",
    "        print(\"CUDA not available. Model loaded onto CPU.\")\n",
    "\n",
    "    model.config.use_cache = True\n",
    "    model.eval()\n",
    "\n",
    "    print(f\"Base model '{model_id}' loaded successfully (No Fine-Tuning).\")\n",
    "\n",
    "    return model, tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e3a574e",
   "metadata": {},
   "source": [
    "# Evaulation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b54d2424",
   "metadata": {},
   "source": [
    "## 5.1 Predict sentiment\n",
    "- Gets the sentiment for a single article\n",
    "- Used for evaulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d4fbddb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sentiment(row, model, tokenizer):\n",
    "\n",
    "    tokenizer.padding_side = \"left\"   # for inference\n",
    "\n",
    "    prompt = generate_prompt(row)\n",
    "\n",
    "    inputs = tokenizer(\n",
    "        prompt,\n",
    "        return_tensors=\"pt\",\n",
    "        truncation=True,  # to avoid crashing model due to very large article\n",
    "        max_length=8192\n",
    "    )\n",
    "    inputs = {k: v.to(model.device) for k, v in inputs.items()}\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model.generate(\n",
    "            **inputs, \n",
    "            max_new_tokens=512,     # only needs to generate enough for sentiment\n",
    "            temperature=0.1,        # incase there was sampling\n",
    "            do_sample=False,        # no sampling - so no randomness\n",
    "            pad_token_id=tokenizer.eos_token_id\n",
    "        )\n",
    "\n",
    "    response = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    response = response[len(prompt):].strip()    # skips over prompt\n",
    "\n",
    "    # Validate response is not empty\n",
    "    if not response:\n",
    "        return {}\n",
    "\n",
    "    # Parse response to get labels into a dict\n",
    "    sentiment = {}\n",
    "    for line in response.split('\\n'):\n",
    "        try:\n",
    "            if line.strip():\n",
    "                currency, label = line.split(':')\n",
    "                currency = currency.strip()\n",
    "                label = label.strip()\n",
    "                sentiment[currency] = label\n",
    "        except ValueError:\n",
    "            print(f\"Error in response: {response} on line: {line}\")\n",
    "            return {}\n",
    "\n",
    "    return sentiment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86f8a2a7",
   "metadata": {},
   "source": [
    "## 5.2 Get evaulation statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ee60878",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluation(model, tokenizer, df_eval):\n",
    "    currency_codes = ['EUR', 'USD', 'GBP', 'JPY', 'AUD', 'CAD', 'CHF', 'NZD', 'NOK', 'SEK']\n",
    "\n",
    "    all_actual = []\n",
    "    all_predictions = []\n",
    "\n",
    "    tokenizer.padding_side = \"left\"   # for inference\n",
    "\n",
    "    skipped_rows = 0\n",
    "    for i, row in df_eval.iterrows():\n",
    "        sentiment = get_sentiment(row, model, tokenizer)\n",
    "        \n",
    "        # Skip this row if LLM response was invalid\n",
    "        if sentiment == {}:\n",
    "            skipped_rows += 1\n",
    "            print(f\"Skipping row {i} due to invalid LLM response format\")\n",
    "            continue\n",
    "            \n",
    "        for c in currency_codes:\n",
    "            for t in ['past', 'future']:\n",
    "                all_actual.append(row[f'{c}_{t}_label'])\n",
    "                all_predictions.append(sentiment.get(f'{c}_{t}', 'unchanged'))\n",
    "\n",
    "        \n",
    "        \n",
    "    accuracy = accuracy_score(all_actual, all_predictions)\n",
    "    f1 = f1_score(all_actual, all_predictions, average='macro')\n",
    "    precision_per_class, recall_per_class, f1_per_class, support_per_class = precision_recall_fscore_support(all_actual, all_predictions, labels=['appreciation', 'depreciation', 'unchanged'])\n",
    "\n",
    "    stats = {\n",
    "        'accuracy': accuracy,\n",
    "        'f1': f1,\n",
    "        'precision_per_class': dict(zip(['appreciation', 'depreciation', 'unchanged'], precision_per_class)),\n",
    "        'recall_per_class': dict(zip(['appreciation', 'depreciation', 'unchanged'], recall_per_class)),\n",
    "        'f1_per_class': dict(zip(['appreciation', 'depreciation', 'unchanged'], f1_per_class)),\n",
    "        'support_per_class': dict(zip(['appreciation', 'depreciation', 'unchanged'], support_per_class))\n",
    "    }\n",
    "\n",
    "    report = classification_report(all_actual, all_predictions)\n",
    "\n",
    "    if skipped_rows > 0:\n",
    "        print(f\"\\nWarning: Skipped {skipped_rows} row(s) out of {len(df_eval)} total due to invalid LLM response\")\n",
    "\n",
    "    print()\n",
    "    print()\n",
    "\n",
    "    print(stats)\n",
    "\n",
    "    print()\n",
    "    print()\n",
    "\n",
    "    print(report)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
