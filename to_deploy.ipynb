{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e3be8afe",
   "metadata": {},
   "source": [
    "# Implementing \"FX sentiment analysis with large language models\" (Ballinari et al.)\n",
    "This paper can be found at "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99a21868",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "423e5cb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import re\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig, TrainingArguments, EarlyStoppingCallback\n",
    "from peft import LoraConfig, prepare_model_for_kbit_training\n",
    "from sklearn.model_selection import train_test_split\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "from huggingface_hub import login\n",
    "from trl import SFTTrainer\n",
    "from datasets import Dataset\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_recall_fscore_support, classification_report\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb648241",
   "metadata": {},
   "source": [
    "## 1. Dataset Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fccdfb1",
   "metadata": {},
   "source": [
    "### 1.1. Filtering\n",
    "- Load the datasets\n",
    "- Drop articles with <20 words\n",
    "- Remove duplicate articles \n",
    "- Convert time to datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39896162",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the dailyfx news articles dataset (Title,Author,Date,Full Text,URL)\n",
    "df_news = pd.read_csv('datasets/news_articles/dailyfx_articles_012011-062024.csv')\n",
    "df_news = df_news[['Title', 'Date', 'Full Text', 'URL']]\n",
    "\n",
    "# Load the fxstreet news articles dataset into same df (Title,Date,Full Text,URL)\n",
    "temp = pd.read_csv('datasets/news_articles/fxstreet_articles.csv')\n",
    "temp = temp[['Title', 'Date', 'Full Text', 'URL']]\n",
    "df_news = pd.concat([df_news, temp], ignore_index=True)\n",
    "\n",
    "# # Load investing.com news articles dataset into same df (Title,Full Text,URL,Date,Author)\n",
    "temp = pd.read_csv('datasets/news_articles/investingcom_finaldata_2011-062024.csv')\n",
    "temp = temp[['Title', 'Date', 'Full Text', 'URL']]\n",
    "df_news = pd.concat([df_news, temp], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "f11701c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop articles with <20 words\n",
    "df_news = df_news[df_news['Full Text'].str.split().str.len() >= 20]\n",
    "\n",
    "# Remove duplicate articles\n",
    "df_news = df_news.drop_duplicates(subset=['Full Text'])\n",
    "df_news = df_news.drop_duplicates(subset=['Title'])\n",
    "df_news = df_news.drop_duplicates(subset=['URL'])\n",
    "\n",
    "# Convert time to datetime\n",
    "df_news['Date'] = pd.to_datetime(df_news['Date'], utc=True)\n",
    "\n",
    "# Only keep articles before 2020\n",
    "# df_news = df_news[df_news['Date'] < pd.to_datetime('2020-01-01', utc=True)]\n",
    "\n",
    "# Truncate articles to max 32,767 characters\n",
    "df_news['Full Text'] = df_news['Full Text'].str[:32767]\n",
    "\n",
    "# Randomly sample 30000 articles\n",
    "df_news = df_news.sample(n=30000, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "3eb17a9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_news['Date'] = (\n",
    "    df_news['Date']                        \n",
    "    .dt.tz_convert('America/New_York')     # Convert to NY time like paper\n",
    "    .dt.tz_localize(None)                  # Remove timezone info to allow for merging later\n",
    "    .dt.normalize()                        # Normalise to midnight\n",
    ")\n",
    "\n",
    "# Sort by date\n",
    "df_news = df_news.sort_values(by='Date')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bea60f85",
   "metadata": {},
   "source": [
    "### 1.2. Creating mentioned_currency column\n",
    "- Use regex to capture all the currencies used in an article\n",
    "- Make use of common synomyms\n",
    "- Filter articles that don't mention any of the G10 currencies "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "e119ddf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionary mapping ISO codes to the regex patterns (synonyms) from Figure A.1\n",
    "currency_synonyms = {\n",
    "    \"EUR\": [r\"EUR\", r\"Euro\"],\n",
    "    \"USD\": [r\"USD\", r\"Dollar\", r\"Dollars\", r\"US Dollar\", r\"US-Dollar\", r\"U\\.S\\. Dollar\", \n",
    "            r\"US Dollars\", r\"US-Dollars\", r\"U\\.S\\. Dollars\", r\"Greenback\"],\n",
    "    \"JPY\": [r\"JPY\", r\"Yen\", r\"Japanese Yen\"],\n",
    "    \"GBP\": [r\"GBP\", r\"Pound\", r\"Pounds\", r\"Sterling\", r\"British Pound\", r\"British Pounds\"],\n",
    "    \"AUD\": [r\"AUD\", r\"Australian Dollar\", r\"Australian Dollars\", r\"Aussie\"],\n",
    "    \"CAD\": [r\"CAD\", r\"Canadian Dollar\", r\"Canadian Dollars\"],\n",
    "    \"CHF\": [r\"CHF\", r\"Swiss Franc\", r\"Swiss Francs\", r\"Swissie\"],\n",
    "    \"NZD\": [r\"NZD\", r\"New Zealand Dollar\", r\"New Zealand Dollars\", r\"Kiwi\"],\n",
    "    \"NOK\": [r\"NOK\", r\"Norwegian Krone\", r\"Norwegian Kroner\"],\n",
    "    \"SEK\": [r\"SEK\", r\"Swedish Krona\", r\"Swedish Kronor\"]\n",
    "}\n",
    "\n",
    "# Get list of mentioned currencies from text\n",
    "def get_mentioned_currencies(text):\n",
    "    mentioned_currencies = list()\n",
    "\n",
    "    for currency, patterns in currency_synonyms.items():\n",
    "        for pattern in patterns:\n",
    "            if re.search(pattern, text, re.IGNORECASE):\n",
    "                mentioned_currencies.append(currency)\n",
    "                break\n",
    "\n",
    "    return mentioned_currencies\n",
    "\n",
    "df_news['mentioned_currencies'] = df_news['Full Text'].apply(get_mentioned_currencies)\n",
    "\n",
    "# Filter articles to keep only those where 'mentioned_currencies' is non empty\n",
    "df_news = df_news[df_news['mentioned_currencies'].apply(lambda x: len(x) > 0)]\n",
    "\n",
    "# So that it is incrimenting by 1 properly due to dropped values from before\n",
    "df_news = df_news.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7de90cbd",
   "metadata": {},
   "source": [
    "### 1.3. Getting historical prices\n",
    "Using nominal narrow effective exchange rate (daily) for each country.\n",
    "\n",
    "Narrow effective exchange rate is a good proxy for the tradable currency index that the authors used.\n",
    "\n",
    "Allows us to put a number to the currency rather than using a pair as then the currency can be effected by the other in the pair. \n",
    "\n",
    "It is done by taking the geometric mean from the exchange rate of various other currencies (narrow means only a small number of industrialised countries so that the average isn't skewed by some other non industrialised country going down)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "5ec17aa9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>USD</th>\n",
       "      <th>EUR</th>\n",
       "      <th>JPY</th>\n",
       "      <th>GBP</th>\n",
       "      <th>CAD</th>\n",
       "      <th>AUD</th>\n",
       "      <th>CHF</th>\n",
       "      <th>SEK</th>\n",
       "      <th>NOK</th>\n",
       "      <th>NZD</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2011-01-03</th>\n",
       "      <td>82.07</td>\n",
       "      <td>103.41</td>\n",
       "      <td>120.99</td>\n",
       "      <td>105.23</td>\n",
       "      <td>129.89</td>\n",
       "      <td>130.38</td>\n",
       "      <td>87.30</td>\n",
       "      <td>116.49</td>\n",
       "      <td>136.00</td>\n",
       "      <td>98.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-01-04</th>\n",
       "      <td>82.05</td>\n",
       "      <td>103.98</td>\n",
       "      <td>119.81</td>\n",
       "      <td>105.84</td>\n",
       "      <td>129.59</td>\n",
       "      <td>128.97</td>\n",
       "      <td>86.05</td>\n",
       "      <td>116.47</td>\n",
       "      <td>135.74</td>\n",
       "      <td>97.42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-01-05</th>\n",
       "      <td>82.77</td>\n",
       "      <td>102.87</td>\n",
       "      <td>120.35</td>\n",
       "      <td>106.70</td>\n",
       "      <td>128.98</td>\n",
       "      <td>128.61</td>\n",
       "      <td>86.01</td>\n",
       "      <td>116.37</td>\n",
       "      <td>135.51</td>\n",
       "      <td>97.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-01-06</th>\n",
       "      <td>83.09</td>\n",
       "      <td>102.38</td>\n",
       "      <td>119.32</td>\n",
       "      <td>106.95</td>\n",
       "      <td>130.06</td>\n",
       "      <td>128.83</td>\n",
       "      <td>85.40</td>\n",
       "      <td>116.25</td>\n",
       "      <td>135.96</td>\n",
       "      <td>97.37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-01-07</th>\n",
       "      <td>83.46</td>\n",
       "      <td>101.62</td>\n",
       "      <td>119.31</td>\n",
       "      <td>107.42</td>\n",
       "      <td>130.42</td>\n",
       "      <td>128.88</td>\n",
       "      <td>86.29</td>\n",
       "      <td>115.74</td>\n",
       "      <td>136.06</td>\n",
       "      <td>97.72</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              USD     EUR     JPY     GBP     CAD     AUD    CHF     SEK  \\\n",
       "date                                                                       \n",
       "2011-01-03  82.07  103.41  120.99  105.23  129.89  130.38  87.30  116.49   \n",
       "2011-01-04  82.05  103.98  119.81  105.84  129.59  128.97  86.05  116.47   \n",
       "2011-01-05  82.77  102.87  120.35  106.70  128.98  128.61  86.01  116.37   \n",
       "2011-01-06  83.09  102.38  119.32  106.95  130.06  128.83  85.40  116.25   \n",
       "2011-01-07  83.46  101.62  119.31  107.42  130.42  128.88  86.29  115.74   \n",
       "\n",
       "               NOK    NZD  \n",
       "date                       \n",
       "2011-01-03  136.00  98.33  \n",
       "2011-01-04  135.74  97.42  \n",
       "2011-01-05  135.51  97.75  \n",
       "2011-01-06  135.96  97.37  \n",
       "2011-01-07  136.06  97.72  "
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# All links to get data from for effective exchage rate\n",
    "urls = {\n",
    "    \"USD\": \"https://stats.bis.org/api/v2/data/dataflow/BIS/WS_EER/1.0/D.N.N.US?startPeriod=2011-01-01&endPeriod=2024-06-01&format=csv\",\n",
    "    \"EUR\": \"https://stats.bis.org/api/v2/data/dataflow/BIS/WS_EER/1.0/D.N.N.XM?startPeriod=2011-01-01&endPeriod=2024-06-01&format=csv\",\n",
    "    \"JPY\": \"https://stats.bis.org/api/v2/data/dataflow/BIS/WS_EER/1.0/D.N.N.JP?startPeriod=2011-01-01&endPeriod=2024-06-01&format=csv\",\n",
    "    \"GBP\": \"https://stats.bis.org/api/v2/data/dataflow/BIS/WS_EER/1.0/D.N.N.GB?startPeriod=2011-01-01&endPeriod=2024-06-01&format=csv\",\n",
    "    \"CAD\": \"https://stats.bis.org/api/v2/data/dataflow/BIS/WS_EER/1.0/D.N.N.CA?startPeriod=2011-01-01&endPeriod=2024-06-01&format=csv\",\n",
    "    \"AUD\": \"https://stats.bis.org/api/v2/data/dataflow/BIS/WS_EER/1.0/D.N.N.AU?startPeriod=2011-01-01&endPeriod=2024-06-01&format=csv\",\n",
    "    \"CHF\": \"https://stats.bis.org/api/v2/data/dataflow/BIS/WS_EER/1.0/D.N.N.CH?startPeriod=2011-01-01&endPeriod=2024-06-01&format=csv\", \n",
    "    \"SEK\": \"https://stats.bis.org/api/v2/data/dataflow/BIS/WS_EER/1.0/D.N.N.SE?startPeriod=2011-01-01&endPeriod=2024-06-01&format=csv\",\n",
    "    \"NOK\": \"https://stats.bis.org/api/v2/data/dataflow/BIS/WS_EER/1.0/D.N.N.NO?startPeriod=2011-01-01&endPeriod=2024-06-01&format=csv\",\n",
    "    \"NZD\": \"https://stats.bis.org/api/v2/data/dataflow/BIS/WS_EER/1.0/D.N.N.NZ?startPeriod=2011-01-01&endPeriod=2024-06-01&format=csv\"\n",
    "}\n",
    "\n",
    "# Initialise an empty DataFrame (EER = effective exchange rate)\n",
    "df_EER = pd.DataFrame()\n",
    "\n",
    "for code, url in urls.items():\n",
    "    # Read only the required columns from the CSV\n",
    "    df_temp = pd.read_csv(url, usecols=lambda c: c in [\"TIME_PERIOD\", \"OBS_VALUE\"])\n",
    "    \n",
    "    # Convert OBS_VALUE to float for log calculations later\n",
    "    df_temp[\"OBS_VALUE\"] = pd.to_numeric(df_temp[\"OBS_VALUE\"], errors=\"coerce\")\n",
    "    \n",
    "    # Rename \"OBS_VALUE\" to currency code\n",
    "    df_temp = df_temp.rename(columns={\n",
    "        \"OBS_VALUE\": code,\n",
    "        \"TIME_PERIOD\": \"date\"\n",
    "    })\n",
    "    \n",
    "    # If the main df is empty, set it to this df\n",
    "    if df_EER.empty:\n",
    "        df_EER = df_temp\n",
    "    else:\n",
    "        # Join on \"date\", keep all records (outer join)\n",
    "        df_EER = pd.merge(df_EER, df_temp, on=[\"date\"], how='outer')\n",
    "\n",
    "\n",
    "df_EER['date'] = pd.to_datetime(df_EER['date'])\n",
    "df_EER = df_EER.set_index('date')\n",
    "\n",
    "# drop all NaNs in the data\n",
    "df_EER.dropna(inplace=True)\n",
    "\n",
    "df_EER.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee101bb9",
   "metadata": {},
   "source": [
    "### 1.4 Calculate log returns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2966a6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate daily log returns\n",
    "df_log_returns = np.log(df_EER / df_EER.shift(1))\n",
    "\n",
    "df_log_returns.dropna(inplace=True)  # created in the shifting\n",
    "\n",
    "df_log_returns.to_pickle(\"df_log_returns.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31907a01",
   "metadata": {},
   "source": [
    "### 1.5 Calculate cumulative 5 day windows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "3ff1f87d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Future returns\n",
    "# At index t, we want the sum of t+1, t+2, t+3, t+4, t+5 returns\n",
    "df_future_returns = df_log_returns.rolling(window=5, min_periods=5).sum().shift(-5)\n",
    "df_future_returns.dropna(inplace=True)\n",
    "\n",
    "# Past returns\n",
    "# At index t, we want the sum of t-1, t-2, t-3, t-4, t-5 returns\n",
    "df_past_returns = df_log_returns.rolling(window=5, min_periods=5).sum().shift(1)\n",
    "df_past_returns.dropna(inplace=True)\n",
    "\n",
    "\n",
    "# Merge future and past returns DataFrames into df_log_returns, aligning on date index.\n",
    "df_log_returns = df_log_returns.join(df_future_returns.add_suffix('_future'), how='inner')\n",
    "df_log_returns = df_log_returns.join(df_past_returns.add_suffix('_past'), how='inner')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9df54968",
   "metadata": {},
   "source": [
    "### 1.6 Get sentiment labels\n",
    "\n",
    "Based of future returns:\n",
    "\n",
    "For each timestep:\n",
    "- Top 3 (30%) -> \"appreciation\"\n",
    "- Middle 4 (40%) -> \"unchanged\"\n",
    "- Bottom 3 (30%) -> \"depreciation\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "87564836",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get list of currency codes (G10 currencies)\n",
    "currency_codes = ['USD', 'EUR', 'JPY', 'GBP', 'CAD', 'AUD', 'CHF', 'SEK', 'NOK', 'NZD']\n",
    "\n",
    "# Initialize label columns for each currency\n",
    "for currency in currency_codes:\n",
    "    df_log_returns[f'{currency}_label'] = None\n",
    "\n",
    "# For each date (row), rank currencies by their future returns and assign labels\n",
    "for date in df_log_returns.index:\n",
    "    # Get future returns for this date\n",
    "    future_returns = {}\n",
    "    for currency in currency_codes:\n",
    "        value = df_log_returns.loc[date, f'{currency}_future']\n",
    "        if pd.notna(value):\n",
    "            future_returns[currency] = value\n",
    "\n",
    "    # Get past returns for this date\n",
    "    past_returns = {}\n",
    "    for currency in currency_codes:\n",
    "        value = df_log_returns.loc[date, f'{currency}_past']\n",
    "        if pd.notna(value):\n",
    "            past_returns[currency] = value\n",
    "    \n",
    "    # Rank currencies by future returns (highest to lowest)\n",
    "    sorted_currencies_future = sorted(future_returns.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    # Rank currencies by past returns (highest to lowest)\n",
    "    sorted_currencies_past = sorted(past_returns.items(), key=lambda x: x[1], reverse=True)\n",
    "    \n",
    "    # Assign labels based on ranking\n",
    "    # Top 3 (30%) -> \"appreciation\"\n",
    "    # Middle 4 (40%) -> \"unchanged\"\n",
    "    # Bottom 3 (30%) -> \"depreciation\"\n",
    "    for i, (currency, _) in enumerate(sorted_currencies_future):\n",
    "        if i < 3:  # Top 3 (0, 1, 2)\n",
    "            df_log_returns.loc[date, f'{currency}_future_label'] = 'appreciation'\n",
    "        elif i >= 7:  # Bottom 3 (7, 8, 9)\n",
    "            df_log_returns.loc[date, f'{currency}_future_label'] = 'depreciation'\n",
    "        else:  # Middle 4 (3, 4, 5, 6)\n",
    "            df_log_returns.loc[date, f'{currency}_future_label'] = 'unchanged'\n",
    "    \n",
    "    for i, (currency, _) in enumerate(sorted_currencies_past):\n",
    "        if i < 3:  # Top 3 (0, 1, 2)\n",
    "            df_log_returns.loc[date, f'{currency}_past_label'] = 'appreciation'\n",
    "        elif i >= 7:  # Bottom 3 (7, 8, 9)\n",
    "            df_log_returns.loc[date, f'{currency}_past_label'] = 'depreciation'\n",
    "        else:  # Middle 4 (3, 4, 5, 6)\n",
    "            df_log_returns.loc[date, f'{currency}_past_label'] = 'unchanged'\n",
    "\n",
    "# Only keep labels\n",
    "df_labels = df_log_returns[\n",
    "    [f'{currency}_future_label' for currency in currency_codes] + \n",
    "    [f'{currency}_past_label' for currency in currency_codes] \n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "faec7be6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['date', 'USD_future_label', 'EUR_future_label', 'JPY_future_label',\n",
       "       'GBP_future_label', 'CAD_future_label', 'AUD_future_label',\n",
       "       'CHF_future_label', 'SEK_future_label', 'NOK_future_label',\n",
       "       'NZD_future_label', 'USD_past_label', 'EUR_past_label',\n",
       "       'JPY_past_label', 'GBP_past_label', 'CAD_past_label', 'AUD_past_label',\n",
       "       'CHF_past_label', 'SEK_past_label', 'NOK_past_label', 'NZD_past_label'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get rid of time info\n",
    "df_labels.index = df_labels.index.normalize()\n",
    "\n",
    "# Have date as a column\n",
    "df_labels = df_labels.reset_index()\n",
    "\n",
    "df_labels.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d6da9ca",
   "metadata": {},
   "source": [
    "### 1.7 Assign labels to news articles\n",
    "- df_labels - labels for sentiment for each valid day\n",
    "- df_news_future and past - mapping between all real dates and valid dates based on the way we backfill\n",
    "- df_news - now will contain these new sentiment labels joined using the dates from the news_future/past"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "beb1b7fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# maps news date to future trading date\n",
    "df_news_future = pd.merge_asof(\n",
    "    df_news[['Date']],\n",
    "    df_labels[['date']],\n",
    "    left_on='Date',\n",
    "    right_on='date',\n",
    "    direction='forward'\n",
    ").rename(columns={'Date': 'news_date', 'date': 'trading_date_future'})\n",
    "\n",
    "\n",
    "# maps news date to past trading date\n",
    "df_news_past = pd.merge_asof(\n",
    "    df_news[['Date']],\n",
    "    df_labels[['date']],\n",
    "    left_on='Date',\n",
    "    right_on='date',\n",
    "    direction='backward'\n",
    ").rename(columns={'Date': 'news_date', 'date': 'trading_date_past'})\n",
    "\n",
    "# Perform a concat of df_news and df_news_future and df_news_past\n",
    "# Example: Only concat 'news_date' from df_news_future, and 'trading_date_past' from df_news_past\n",
    "df_news = pd.concat([\n",
    "    df_news,\n",
    "    df_news_future[['trading_date_future']],\n",
    "    df_news_past[['trading_date_past']]\n",
    "], axis=1)\n",
    "\n",
    "\n",
    "# Merge the future labels into the news dataframe\n",
    "future_cols = ['date'] + [col for col in df_labels.columns if col.endswith('_future_label')]\n",
    "df_labels_future = df_labels[future_cols]\n",
    "\n",
    "df_news = df_news.merge(df_labels_future, left_on='trading_date_future', right_on='date', how='left')\n",
    "df_news = df_news.drop(columns=['date'])  # Drop the date column as we don't need it\n",
    "\n",
    "# Merge the past labels into the news dataframe\n",
    "past_cols = ['date'] + [col for col in df_labels.columns if col.endswith('_past_label')]\n",
    "df_labels_past = df_labels[past_cols]\n",
    "\n",
    "df_news = df_news.merge(df_labels_past, left_on='trading_date_past', right_on='date', how='left')\n",
    "df_news = df_news.drop(columns=['date'])  # Drop the date column as we already have trading_date"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5091e1d",
   "metadata": {},
   "source": [
    "### 1.8 Cleaning final DataFrame\n",
    "- drop rows with nulls\n",
    "- Removing unnecessary columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "07681d46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Date</th>\n",
       "      <th>Full Text</th>\n",
       "      <th>mentioned_currencies</th>\n",
       "      <th>Trading Date</th>\n",
       "      <th>USD_future_label</th>\n",
       "      <th>EUR_future_label</th>\n",
       "      <th>JPY_future_label</th>\n",
       "      <th>GBP_future_label</th>\n",
       "      <th>CAD_future_label</th>\n",
       "      <th>...</th>\n",
       "      <th>USD_past_label</th>\n",
       "      <th>EUR_past_label</th>\n",
       "      <th>JPY_past_label</th>\n",
       "      <th>GBP_past_label</th>\n",
       "      <th>CAD_past_label</th>\n",
       "      <th>AUD_past_label</th>\n",
       "      <th>CHF_past_label</th>\n",
       "      <th>SEK_past_label</th>\n",
       "      <th>NOK_past_label</th>\n",
       "      <th>NZD_past_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>EUR/CHF Finds Support</td>\n",
       "      <td>2011-01-12</td>\n",
       "      <td>Sha...</td>\n",
       "      <td>[EUR, CHF]</td>\n",
       "      <td>2011-01-12</td>\n",
       "      <td>depreciation</td>\n",
       "      <td>appreciation</td>\n",
       "      <td>appreciation</td>\n",
       "      <td>unchanged</td>\n",
       "      <td>depreciation</td>\n",
       "      <td>...</td>\n",
       "      <td>appreciation</td>\n",
       "      <td>depreciation</td>\n",
       "      <td>unchanged</td>\n",
       "      <td>appreciation</td>\n",
       "      <td>appreciation</td>\n",
       "      <td>depreciation</td>\n",
       "      <td>depreciation</td>\n",
       "      <td>unchanged</td>\n",
       "      <td>unchanged</td>\n",
       "      <td>unchanged</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Risk Reward Ratios</td>\n",
       "      <td>2011-01-18</td>\n",
       "      <td>Sha...</td>\n",
       "      <td>[EUR, USD]</td>\n",
       "      <td>2011-01-18</td>\n",
       "      <td>unchanged</td>\n",
       "      <td>appreciation</td>\n",
       "      <td>unchanged</td>\n",
       "      <td>depreciation</td>\n",
       "      <td>depreciation</td>\n",
       "      <td>...</td>\n",
       "      <td>depreciation</td>\n",
       "      <td>appreciation</td>\n",
       "      <td>unchanged</td>\n",
       "      <td>unchanged</td>\n",
       "      <td>unchanged</td>\n",
       "      <td>depreciation</td>\n",
       "      <td>depreciation</td>\n",
       "      <td>appreciation</td>\n",
       "      <td>unchanged</td>\n",
       "      <td>appreciation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>How to Identify a Currency Pair that is in a T...</td>\n",
       "      <td>2011-01-19</td>\n",
       "      <td>Sha...</td>\n",
       "      <td>[EUR, USD]</td>\n",
       "      <td>2011-01-19</td>\n",
       "      <td>unchanged</td>\n",
       "      <td>appreciation</td>\n",
       "      <td>unchanged</td>\n",
       "      <td>depreciation</td>\n",
       "      <td>unchanged</td>\n",
       "      <td>...</td>\n",
       "      <td>depreciation</td>\n",
       "      <td>appreciation</td>\n",
       "      <td>depreciation</td>\n",
       "      <td>appreciation</td>\n",
       "      <td>unchanged</td>\n",
       "      <td>unchanged</td>\n",
       "      <td>depreciation</td>\n",
       "      <td>unchanged</td>\n",
       "      <td>unchanged</td>\n",
       "      <td>appreciation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>EURUSD Flashes a Bearish Pattern</td>\n",
       "      <td>2011-01-19</td>\n",
       "      <td>Sha...</td>\n",
       "      <td>[EUR, USD]</td>\n",
       "      <td>2011-01-19</td>\n",
       "      <td>unchanged</td>\n",
       "      <td>appreciation</td>\n",
       "      <td>unchanged</td>\n",
       "      <td>depreciation</td>\n",
       "      <td>unchanged</td>\n",
       "      <td>...</td>\n",
       "      <td>depreciation</td>\n",
       "      <td>appreciation</td>\n",
       "      <td>depreciation</td>\n",
       "      <td>appreciation</td>\n",
       "      <td>unchanged</td>\n",
       "      <td>unchanged</td>\n",
       "      <td>depreciation</td>\n",
       "      <td>unchanged</td>\n",
       "      <td>unchanged</td>\n",
       "      <td>appreciation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Should you Trade the Trend or Trade the Double...</td>\n",
       "      <td>2011-01-24</td>\n",
       "      <td>Sha...</td>\n",
       "      <td>[EUR, USD]</td>\n",
       "      <td>2011-01-24</td>\n",
       "      <td>unchanged</td>\n",
       "      <td>unchanged</td>\n",
       "      <td>unchanged</td>\n",
       "      <td>depreciation</td>\n",
       "      <td>depreciation</td>\n",
       "      <td>...</td>\n",
       "      <td>depreciation</td>\n",
       "      <td>appreciation</td>\n",
       "      <td>appreciation</td>\n",
       "      <td>unchanged</td>\n",
       "      <td>unchanged</td>\n",
       "      <td>unchanged</td>\n",
       "      <td>depreciation</td>\n",
       "      <td>appreciation</td>\n",
       "      <td>unchanged</td>\n",
       "      <td>depreciation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25970</th>\n",
       "      <td>Dow Sustains Losses but Nasdaq 100 Hits New Hi...</td>\n",
       "      <td>2024-05-23</td>\n",
       "      <td>Sha...</td>\n",
       "      <td>[USD, AUD]</td>\n",
       "      <td>2024-05-23</td>\n",
       "      <td>unchanged</td>\n",
       "      <td>depreciation</td>\n",
       "      <td>unchanged</td>\n",
       "      <td>unchanged</td>\n",
       "      <td>depreciation</td>\n",
       "      <td>...</td>\n",
       "      <td>unchanged</td>\n",
       "      <td>unchanged</td>\n",
       "      <td>depreciation</td>\n",
       "      <td>appreciation</td>\n",
       "      <td>depreciation</td>\n",
       "      <td>unchanged</td>\n",
       "      <td>depreciation</td>\n",
       "      <td>unchanged</td>\n",
       "      <td>appreciation</td>\n",
       "      <td>appreciation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25971</th>\n",
       "      <td>US Dollar Technical Outlook: EUR/USD, GBP/USD,...</td>\n",
       "      <td>2024-05-23</td>\n",
       "      <td>Sha...</td>\n",
       "      <td>[EUR, USD, GBP, NZD]</td>\n",
       "      <td>2024-05-23</td>\n",
       "      <td>unchanged</td>\n",
       "      <td>depreciation</td>\n",
       "      <td>unchanged</td>\n",
       "      <td>unchanged</td>\n",
       "      <td>depreciation</td>\n",
       "      <td>...</td>\n",
       "      <td>unchanged</td>\n",
       "      <td>unchanged</td>\n",
       "      <td>depreciation</td>\n",
       "      <td>appreciation</td>\n",
       "      <td>depreciation</td>\n",
       "      <td>unchanged</td>\n",
       "      <td>depreciation</td>\n",
       "      <td>unchanged</td>\n",
       "      <td>appreciation</td>\n",
       "      <td>appreciation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25972</th>\n",
       "      <td>BoJ Faces Dilemma: Hiking Rates into Economic ...</td>\n",
       "      <td>2024-05-24</td>\n",
       "      <td>Sha...</td>\n",
       "      <td>[USD, JPY]</td>\n",
       "      <td>2024-05-24</td>\n",
       "      <td>depreciation</td>\n",
       "      <td>depreciation</td>\n",
       "      <td>unchanged</td>\n",
       "      <td>depreciation</td>\n",
       "      <td>unchanged</td>\n",
       "      <td>...</td>\n",
       "      <td>unchanged</td>\n",
       "      <td>unchanged</td>\n",
       "      <td>depreciation</td>\n",
       "      <td>appreciation</td>\n",
       "      <td>depreciation</td>\n",
       "      <td>unchanged</td>\n",
       "      <td>depreciation</td>\n",
       "      <td>unchanged</td>\n",
       "      <td>appreciation</td>\n",
       "      <td>appreciation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25973</th>\n",
       "      <td>EUR/CHF IG Client Sentiment: Our data shows tr...</td>\n",
       "      <td>2024-05-24</td>\n",
       "      <td>Sha...</td>\n",
       "      <td>[EUR, CHF]</td>\n",
       "      <td>2024-05-24</td>\n",
       "      <td>depreciation</td>\n",
       "      <td>depreciation</td>\n",
       "      <td>unchanged</td>\n",
       "      <td>depreciation</td>\n",
       "      <td>unchanged</td>\n",
       "      <td>...</td>\n",
       "      <td>unchanged</td>\n",
       "      <td>unchanged</td>\n",
       "      <td>depreciation</td>\n",
       "      <td>appreciation</td>\n",
       "      <td>depreciation</td>\n",
       "      <td>unchanged</td>\n",
       "      <td>depreciation</td>\n",
       "      <td>unchanged</td>\n",
       "      <td>appreciation</td>\n",
       "      <td>appreciation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25974</th>\n",
       "      <td>A Hawkish Tone from Central Banks Weigh on Sto...</td>\n",
       "      <td>2024-05-24</td>\n",
       "      <td>Sha...</td>\n",
       "      <td>[USD]</td>\n",
       "      <td>2024-05-24</td>\n",
       "      <td>depreciation</td>\n",
       "      <td>depreciation</td>\n",
       "      <td>unchanged</td>\n",
       "      <td>depreciation</td>\n",
       "      <td>unchanged</td>\n",
       "      <td>...</td>\n",
       "      <td>unchanged</td>\n",
       "      <td>unchanged</td>\n",
       "      <td>depreciation</td>\n",
       "      <td>appreciation</td>\n",
       "      <td>depreciation</td>\n",
       "      <td>unchanged</td>\n",
       "      <td>depreciation</td>\n",
       "      <td>unchanged</td>\n",
       "      <td>appreciation</td>\n",
       "      <td>appreciation</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>25971 rows Ã— 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   Title       Date  \\\n",
       "4                                  EUR/CHF Finds Support 2011-01-12   \n",
       "5                                     Risk Reward Ratios 2011-01-18   \n",
       "6      How to Identify a Currency Pair that is in a T... 2011-01-19   \n",
       "7                       EURUSD Flashes a Bearish Pattern 2011-01-19   \n",
       "8      Should you Trade the Trend or Trade the Double... 2011-01-24   \n",
       "...                                                  ...        ...   \n",
       "25970  Dow Sustains Losses but Nasdaq 100 Hits New Hi... 2024-05-23   \n",
       "25971  US Dollar Technical Outlook: EUR/USD, GBP/USD,... 2024-05-23   \n",
       "25972  BoJ Faces Dilemma: Hiking Rates into Economic ... 2024-05-24   \n",
       "25973  EUR/CHF IG Client Sentiment: Our data shows tr... 2024-05-24   \n",
       "25974  A Hawkish Tone from Central Banks Weigh on Sto... 2024-05-24   \n",
       "\n",
       "                                               Full Text  \\\n",
       "4                                                 Sha...   \n",
       "5                                                 Sha...   \n",
       "6                                                 Sha...   \n",
       "7                                                 Sha...   \n",
       "8                                                 Sha...   \n",
       "...                                                  ...   \n",
       "25970                                             Sha...   \n",
       "25971                                             Sha...   \n",
       "25972                                             Sha...   \n",
       "25973                                             Sha...   \n",
       "25974                                             Sha...   \n",
       "\n",
       "       mentioned_currencies Trading Date USD_future_label EUR_future_label  \\\n",
       "4                [EUR, CHF]   2011-01-12     depreciation     appreciation   \n",
       "5                [EUR, USD]   2011-01-18        unchanged     appreciation   \n",
       "6                [EUR, USD]   2011-01-19        unchanged     appreciation   \n",
       "7                [EUR, USD]   2011-01-19        unchanged     appreciation   \n",
       "8                [EUR, USD]   2011-01-24        unchanged        unchanged   \n",
       "...                     ...          ...              ...              ...   \n",
       "25970            [USD, AUD]   2024-05-23        unchanged     depreciation   \n",
       "25971  [EUR, USD, GBP, NZD]   2024-05-23        unchanged     depreciation   \n",
       "25972            [USD, JPY]   2024-05-24     depreciation     depreciation   \n",
       "25973            [EUR, CHF]   2024-05-24     depreciation     depreciation   \n",
       "25974                 [USD]   2024-05-24     depreciation     depreciation   \n",
       "\n",
       "      JPY_future_label GBP_future_label CAD_future_label  ... USD_past_label  \\\n",
       "4         appreciation        unchanged     depreciation  ...   appreciation   \n",
       "5            unchanged     depreciation     depreciation  ...   depreciation   \n",
       "6            unchanged     depreciation        unchanged  ...   depreciation   \n",
       "7            unchanged     depreciation        unchanged  ...   depreciation   \n",
       "8            unchanged     depreciation     depreciation  ...   depreciation   \n",
       "...                ...              ...              ...  ...            ...   \n",
       "25970        unchanged        unchanged     depreciation  ...      unchanged   \n",
       "25971        unchanged        unchanged     depreciation  ...      unchanged   \n",
       "25972        unchanged     depreciation        unchanged  ...      unchanged   \n",
       "25973        unchanged     depreciation        unchanged  ...      unchanged   \n",
       "25974        unchanged     depreciation        unchanged  ...      unchanged   \n",
       "\n",
       "      EUR_past_label JPY_past_label GBP_past_label CAD_past_label  \\\n",
       "4       depreciation      unchanged   appreciation   appreciation   \n",
       "5       appreciation      unchanged      unchanged      unchanged   \n",
       "6       appreciation   depreciation   appreciation      unchanged   \n",
       "7       appreciation   depreciation   appreciation      unchanged   \n",
       "8       appreciation   appreciation      unchanged      unchanged   \n",
       "...              ...            ...            ...            ...   \n",
       "25970      unchanged   depreciation   appreciation   depreciation   \n",
       "25971      unchanged   depreciation   appreciation   depreciation   \n",
       "25972      unchanged   depreciation   appreciation   depreciation   \n",
       "25973      unchanged   depreciation   appreciation   depreciation   \n",
       "25974      unchanged   depreciation   appreciation   depreciation   \n",
       "\n",
       "      AUD_past_label CHF_past_label SEK_past_label NOK_past_label  \\\n",
       "4       depreciation   depreciation      unchanged      unchanged   \n",
       "5       depreciation   depreciation   appreciation      unchanged   \n",
       "6          unchanged   depreciation      unchanged      unchanged   \n",
       "7          unchanged   depreciation      unchanged      unchanged   \n",
       "8          unchanged   depreciation   appreciation      unchanged   \n",
       "...              ...            ...            ...            ...   \n",
       "25970      unchanged   depreciation      unchanged   appreciation   \n",
       "25971      unchanged   depreciation      unchanged   appreciation   \n",
       "25972      unchanged   depreciation      unchanged   appreciation   \n",
       "25973      unchanged   depreciation      unchanged   appreciation   \n",
       "25974      unchanged   depreciation      unchanged   appreciation   \n",
       "\n",
       "      NZD_past_label  \n",
       "4          unchanged  \n",
       "5       appreciation  \n",
       "6       appreciation  \n",
       "7       appreciation  \n",
       "8       depreciation  \n",
       "...              ...  \n",
       "25970   appreciation  \n",
       "25971   appreciation  \n",
       "25972   appreciation  \n",
       "25973   appreciation  \n",
       "25974   appreciation  \n",
       "\n",
       "[25971 rows x 25 columns]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_news = df_news.rename(columns={'trading_date_future': 'Trading Date'})  # Rename trading_date_future to trading_date\n",
    "\n",
    "# Only keep title, full text and all labels\n",
    "df_news = df_news[['Title', 'Date', 'Full Text', 'mentioned_currencies', 'Trading Date', *future_cols[1:], *past_cols[1:]]]\n",
    "\n",
    "df_news = df_news.dropna()\n",
    "\n",
    "df_news.to_pickle(\"df_news.pkl\")\n",
    "\n",
    "df_news"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2c37e09",
   "metadata": {},
   "source": [
    "### 1.9 Train Test Split\n",
    "- 200 examples for final eval\n",
    "- Otherwise 80/20 train test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c776a646",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of train set:  2\n",
      "Size of test set:  2\n",
      "Size of eval set:  200\n"
     ]
    }
   ],
   "source": [
    "df_news = pd.read_pickle(\"df_news.pkl\")  # IMPORTANT - TODO CHANGE ME\n",
    "\n",
    "df_news_before_2020 = df_news[df_news['Date'] < pd.to_datetime('2020-01-01', utc=True)]     # we train the model on this for now\n",
    "# df_news_after_2020 = df_news[df_news['Date'] >= pd.to_datetime('2020-01-01', utc=True)]   # we use this for the trading strategy\n",
    "\n",
    "df_rest, df_eval = train_test_split(df_news_before_2020, test_size=200, random_state=42)\n",
    "df_train, df_test = train_test_split(df_rest, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "\n",
    "print(\"Size of train set: \", len(df_train))\n",
    "print(\"Size of test set: \", len(df_test))\n",
    "print(\"Size of eval set: \", len(df_eval))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d84da036",
   "metadata": {},
   "source": [
    "## 2 Generate Prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3230b945",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_prompt(row):\n",
    "    title = row.get('Title', '')\n",
    "    text = row.get('Full Text', '')\n",
    "    currencies = row.get('mentioned_currencies')\n",
    "\n",
    "    target_currencies = ''\n",
    "    for c in currencies:\n",
    "        target_currencies += f'{c}_past: \"appreciation, depreciation, or unchanged\",\\n'\n",
    "        target_currencies += f'{c}_future: \"appreciation, depreciation, or unchanged\",\\n'\n",
    "    target_currencies = target_currencies.strip().rstrip(\",\") # Remove last comma\n",
    "\n",
    "    # Same structure as per paper\n",
    "    return (\n",
    "        f\"Title: {title}\\n\"\n",
    "        f\"Text: {text}\\n\\n\"\n",
    "        \"Instructions:\\n\"\n",
    "        \"Objective: For each mentioned currency, answer the following questions:\\n\"\n",
    "        \"- What has been the current/past movement of the currency (appreciation, depreciation, or unchanged)?\\n\"\n",
    "        \"- What is the future expectation for the currency (appreciation, depreciation, or unchanged)?\\n\\n\"\n",
    "        \"You must answer these two questions for each of the following currencies mentioned in the article:\\n\"\n",
    "        f\"{target_currencies}\\n\\n\"\n",
    "        \"Output Format:\\n\"\n",
    "        \"- Important: Provide your answer in separate rows for each currency as shown above.\\n\"\n",
    "        \"- Do not combine multiple currencies in the same row.\\n\"\n",
    "        '- Each currency should have its own line with \"_past\" or \"_future\" specified.\\n\\n'\n",
    "        \"Example:\\n\"\n",
    "        '- If the article states, \"The EUR is expected to appreciate,\" the output should be:\\n'\n",
    "        '    EUR_past: \"unchanged\",\\n'\n",
    "        '    EUR_future: \"appreciation\"\\n'\n",
    "        '- If the article states, \"EUR/USD depreciated last week,\" the output should be:\\n'\n",
    "        '    EUR_past: \"depreciation\",\\n'\n",
    "        '    USD_past: \"appreciation\"\\n'\n",
    "        '- If only future movements are mentioned for a currency, the past movement should be labelled as \"unchanged\" and vice versa.\\n\\n'\n",
    "        \"Currency Pair Interpretation:\\n\"\n",
    "        \"- If currencies are discussed in pairs, interpret as follows:\\n\"\n",
    "        '    - If \"EUR/USD appreciated,\" label EUR_past as \"appreciation\" and USD_past as \"depreciation\".\\n'\n",
    "        '    - If \"EUR/USD depreciated,\" label EUR_past as \"depreciation\" and USD_past as \"appreciation\".\\n\\n'\n",
    "        \"Synonyms:\\n\"\n",
    "        \"- Recognize the following synonyms for each currency:\\n\"\n",
    "        \"- **EUR**: EUR, Euro\\n\"\n",
    "        \"- **USD**: USD, Dollar, Dollars, US Dollar, US-Dollar, U.S. Dollar, US Dollars, US-Dollars, U.S. Dollars, Greenback\\n\"\n",
    "        \"- **JPY**: JPY, Yen, Japanese Yen\\n\"\n",
    "        \"- **GBP**: GBP, Pound, Pounds, Sterling, British Pound, British Pounds\\n\"\n",
    "        \"- **AUD**: AUD, Australian Dollar, Australian Dollars, Aussie\\n\"\n",
    "        \"- **CAD**: CAD, Canadian Dollar, Canadian Dollars\\n\"\n",
    "        \"- **CHF**: CHF, Swiss Franc, Swiss Francs, Swissie\\n\"\n",
    "        \"- **NZD**: NZD, New Zealand Dollar, New Zealand Dollars, Kiwi\\n\"\n",
    "        \"- **NOK**: NOK, Norwegian Krone, Norwegian Kroner\\n\"\n",
    "        \"- **SEK**: SEK, Swedish Krona, Swedish Kronor\\n\"\n",
    "        \"Answer below in the given format:\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "120af922",
   "metadata": {},
   "source": [
    "## 3 Model setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59412ab6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Note: Environment variable`HF_TOKEN` is set and is the current active token independently from the token you've just configured.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model explicitly loaded onto: cuda:0\n"
     ]
    }
   ],
   "source": [
    "load_dotenv()\n",
    "login(token=os.getenv(\"HF_TOKEN\"))\n",
    "\n",
    "# 'meta-llama/Llama-3.1-8B-Instruct' - real\n",
    "# \"meta-llama/Llama-3.2-1B-Instruct\" - for local testing as smallest possible model\n",
    "model_id =  \"meta-llama/Llama-3.1-8B-Instruct\"\n",
    "\n",
    "# quntisation config\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_use_double_quant=True,      # \"Double Quantization\"\n",
    "    bnb_4bit_quant_type=\"nf4\",           # 4-bit NormalFloat data type\n",
    "    bnb_4bit_compute_dtype=torch.bfloat16 # Compute in bfloat16 for stability\n",
    ")\n",
    "\n",
    "# load tokeniser\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "tokenizer.model_max_length = 8192\n",
    "tokenizer.pad_token = tokenizer.eos_token # Llama has no default pad token\n",
    "tokenizer.padding_side = \"right\"  # TODO Check this\n",
    "\n",
    "# load model \n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_id,\n",
    "    quantization_config=bnb_config,\n",
    "    device_map=\"auto\", # Automatically puts model on GPU\n",
    "    dtype=torch.bfloat16\n",
    ")\n",
    "\n",
    "# Move model to GPU if available\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda:0\")\n",
    "    model = model.to(device)\n",
    "    print(f\"Model explicitly loaded onto: {device}\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    model = model.to(device)\n",
    "    print(\"CUDA not available. Model loaded onto CPU.\")\n",
    "\n",
    "model.config.use_cache = False\n",
    "model.config.pretraining_tp = 1\n",
    "\n",
    "# Prepare for training \n",
    "model = prepare_model_for_kbit_training(model)\n",
    "\n",
    "# LoRA config \n",
    "# Params from Table A.1\n",
    "peft_config = LoraConfig(\n",
    "    r=8,\n",
    "    lora_alpha=16,\n",
    "    lora_dropout=0.1,\n",
    "    bias=\"none\",           # TODO Check this\n",
    "    task_type=\"CAUSAL_LM\", # TODO Check this\n",
    "    \n",
    "    # inject low-rank adaptation matrices into all linear layers TODO check this\n",
    "    target_modules=[\n",
    "        \"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\", # Attention projections\n",
    "        \"gate_proj\", \"up_proj\", \"down_proj\"     # MLP projections\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55ee7cd6",
   "metadata": {},
   "source": [
    "## 4 LLM Fine Tuning\n",
    "- Stopping criterion is used\n",
    "    - Optimisises for least loss in the validation stage rather than most traning epochs\n",
    "    - So if the model with best validation loss is in epoch 1 or 2, then the weights in epoch 3 will be discarded\n",
    "    - Used to prevent overfitting due to this being a small dataset\n",
    "    - Stops traning if the validation loss stagnates due to overfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3680190",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Applying formatting function to train dataset: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00, 26.50 examples/s]\n",
      "Adding EOS to train dataset: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00, 119.03 examples/s]\n",
      "Tokenizing train dataset: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00, 11.37 examples/s]\n",
      "Truncating train dataset: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00, 92.35 examples/s]\n",
      "Applying formatting function to eval dataset: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00, 130.05 examples/s]\n",
      "Adding EOS to eval dataset: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00, 155.58 examples/s]\n",
      "Tokenizing eval dataset: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00, 58.27 examples/s]\n",
      "Truncating eval dataset: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00, 243.13 examples/s]\n",
      "The tokenizer has new PAD/BOS/EOS tokens that differ from the model config and generation config. The model config and generation config were aligned accordingly, being updated with the tokenizer's values. Updated tokens: {'eos_token_id': 128009, 'pad_token_id': 128009}.\n",
      "/mnt/c/Users/Amogh/OneDrive - University of Cambridge/Programming-New/Part-II-Project/venv_wsl/lib/python3.11/site-packages/torch/_dynamo/eval_frame.py:632: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3' max='3' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3/3 00:11, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved.\n"
     ]
    }
   ],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    num_train_epochs=3,\n",
    "    per_device_train_batch_size=1,      # TODO Check this\n",
    "    per_device_eval_batch_size=1,       # TODO Check this\n",
    "    gradient_accumulation_steps=32, \n",
    "    optim=\"paged_adamw_32bit\",          # \n",
    "    save_steps=50,                      # TODO get better number\n",
    "    learning_rate=1e-5,                 #  Note: significantly lower than standard\n",
    "    weight_decay=0.1,                   #  High weight decay\n",
    "    fp16=False,\n",
    "    bf16=True,\n",
    "    max_grad_norm=0.3,                  # TODO apparenly this is the best for lora??? - not said in the paper\n",
    "    warmup_ratio=0.0,                   # \n",
    "    lr_scheduler_type=\"cosine\",         #                  \n",
    "    save_strategy=\"steps\",              # for early stopping   (could be epoch)\n",
    "    eval_strategy=\"steps\",              # for early stopping   (could be epoch)\n",
    "    load_best_model_at_end=True,         # for early stopping\n",
    "    metric_for_best_model=\"eval_loss\",   # for early stopping\n",
    "    greater_is_better=False,     # less loss is better\n",
    "    logging_steps=10,                   # TODO get a better number\n",
    "    group_by_length=True,\n",
    "    report_to=\"none\"                    # Disable wandb unless needed\n",
    ")\n",
    "\n",
    "\n",
    "df_train = Dataset.from_pandas(df_train)\n",
    "df_test = Dataset.from_pandas(df_test)\n",
    "\n",
    "trainer = SFTTrainer(\n",
    "    model=model,\n",
    "    train_dataset=df_train, # Ensure this is loaded\n",
    "    eval_dataset=df_test,\n",
    "    peft_config=peft_config,\n",
    "    formatting_func=generate_prompt,\n",
    "    processing_class=tokenizer,\n",
    "    args=training_args,\n",
    "    # packing=False,\n",
    "    callbacks=[EarlyStoppingCallback(early_stopping_patience=1)] # to stop after epoch 1 if validaiton loss gets worse\n",
    ")\n",
    "\n",
    "\n",
    "trainer.train()\n",
    "\n",
    "trainer.model.save_pretrained('llama_3.1_8B_finetuned')\n",
    "print(\"Model saved.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f9fc2f3",
   "metadata": {},
   "source": [
    "## 5 Evaluate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "121dc035",
   "metadata": {},
   "source": [
    "### 5.1 Predict sentiment\n",
    "- Gets the sentiment for a single article\n",
    "- Used for evaulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a6048aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sentiment(row, model, tokenizer):\n",
    "    prompt = generate_prompt(row)\n",
    "\n",
    "    inputs = tokenizer(\n",
    "        prompt,\n",
    "        return_tensors=\"pt\",\n",
    "        truncation=True,  # to avoid crashing model due to very large article\n",
    "        max_length=8192\n",
    "    )\n",
    "    inputs = {k: v.to(model.device) for k, v in inputs.items()}\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model.generate(\n",
    "            **inputs, \n",
    "            max_new_tokens=512,     # only needs to generate enough for sentiment\n",
    "            temperature=0.1,        # incase there was sampling\n",
    "            do_sample=False,        # no sampling - so no randomness\n",
    "            pad_token_id=tokenizer.eos_token_id\n",
    "        )\n",
    "\n",
    "    response = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    response = response[len(prompt):].strip()    # skips over prompt\n",
    "\n",
    "    # Parse response to get labels into a dict\n",
    "    sentiment = {}\n",
    "    for line in response.split('\\n'):\n",
    "        if line.strip():\n",
    "            currency, label = line.split(':')\n",
    "            currency = currency.strip()\n",
    "            label = label.strip()\n",
    "            sentiment[currency] = label\n",
    "\n",
    "    return sentiment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2aee84e",
   "metadata": {},
   "source": [
    "### 5.2 Get evaulation statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5acc2bed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'accuracy': 1.0, 'f1': 1.0, 'precision_per_class': {'appreciation': np.float64(1.0), 'depreciation': np.float64(1.0), 'unchanged': np.float64(1.0)}, 'recall_per_class': {'appreciation': np.float64(1.0), 'depreciation': np.float64(1.0), 'unchanged': np.float64(1.0)}, 'f1_per_class': {'appreciation': np.float64(1.0), 'depreciation': np.float64(1.0), 'unchanged': np.float64(1.0)}, 'support_per_class': {'appreciation': np.int64(60), 'depreciation': np.int64(60), 'unchanged': np.int64(80)}}\n",
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "appreciation       1.00      1.00      1.00        60\n",
      "depreciation       1.00      1.00      1.00        60\n",
      "   unchanged       1.00      1.00      1.00        80\n",
      "\n",
      "    accuracy                           1.00       200\n",
      "   macro avg       1.00      1.00      1.00       200\n",
      "weighted avg       1.00      1.00      1.00       200\n",
      "\n"
     ]
    }
   ],
   "source": [
    "currency_codes = ['EUR', 'USD', 'GBP', 'JPY', 'AUD', 'CAD', 'CHF', 'NZD', 'NOK', 'SEK']\n",
    "\n",
    "all_actual = []\n",
    "all_predictions = []\n",
    "\n",
    "for i, row in df_eval.iterrows():\n",
    "    sentiment = get_sentiment(row, model, tokenizer)\n",
    "    for c in currency_codes:\n",
    "        for t in ['past', 'future']:\n",
    "            all_actual.append(row[f'{c}_{t}_label'])\n",
    "            all_predictions.append(sentiment.get(f'{c}_{t}', 'unchanged'))\n",
    "\n",
    "    \n",
    "    \n",
    "accuracy = accuracy_score(all_actual, all_predictions)\n",
    "f1 = f1_score(all_actual, all_predictions, average='macro')\n",
    "precision_per_class, recall_per_class, f1_per_class, support_per_class = precision_recall_fscore_support(all_actual, all_predictions, labels=['appreciation', 'depreciation', 'unchanged'])\n",
    "\n",
    "stats = {\n",
    "    'accuracy': accuracy,\n",
    "    'f1': f1,\n",
    "    'precision_per_class': dict(zip(['appreciation', 'depreciation', 'unchanged'], precision_per_class)),\n",
    "    'recall_per_class': dict(zip(['appreciation', 'depreciation', 'unchanged'], recall_per_class)),\n",
    "    'f1_per_class': dict(zip(['appreciation', 'depreciation', 'unchanged'], f1_per_class)),\n",
    "    'support_per_class': dict(zip(['appreciation', 'depreciation', 'unchanged'], support_per_class))\n",
    "}\n",
    "\n",
    "report = classification_report(all_actual, all_predictions)\n",
    "\n",
    "print(stats)\n",
    "\n",
    "print()\n",
    "print()\n",
    "\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cada442",
   "metadata": {},
   "source": [
    "## 6 Downstream Application\n",
    "Using model trained on pre 2020 data to backtest on 2020-2024 market"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a263e685",
   "metadata": {},
   "source": [
    "### 6.1 Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca9edac9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Full Text</th>\n",
       "      <th>mentioned_currencies</th>\n",
       "      <th>Trading Date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>USD/CAD Rate Trades Below 1.3000 Ahead of FOMC...</td>\n",
       "      <td>Sha...</td>\n",
       "      <td>[USD, CAD]</td>\n",
       "      <td>2020-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Swiss Franc Forecast: CHF/JPY, NZD/CHF</td>\n",
       "      <td>Sha...</td>\n",
       "      <td>[USD, CHF, NZD]</td>\n",
       "      <td>2020-01-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Crude Oil Prices Up as US Strike Kills Iran Qu...</td>\n",
       "      <td>Sha...</td>\n",
       "      <td>[USD, JPY, AUD, NZD]</td>\n",
       "      <td>2020-01-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Gold Prices Hold Near 4-Month Highs Despite US...</td>\n",
       "      <td>Sha...</td>\n",
       "      <td>[EUR, USD]</td>\n",
       "      <td>2020-01-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>US Dollar Prices May Reverse Higher as Japanes...</td>\n",
       "      <td>Sha...</td>\n",
       "      <td>[EUR, USD, JPY, GBP]</td>\n",
       "      <td>2020-01-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9497</th>\n",
       "      <td>Dow Sustains Losses but Nasdaq 100 Hits New Hi...</td>\n",
       "      <td>Sha...</td>\n",
       "      <td>[USD, AUD]</td>\n",
       "      <td>2024-05-23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9498</th>\n",
       "      <td>US Dollar Technical Outlook: EUR/USD, GBP/USD,...</td>\n",
       "      <td>Sha...</td>\n",
       "      <td>[EUR, USD, GBP, NZD]</td>\n",
       "      <td>2024-05-23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9499</th>\n",
       "      <td>BoJ Faces Dilemma: Hiking Rates into Economic ...</td>\n",
       "      <td>Sha...</td>\n",
       "      <td>[USD, JPY]</td>\n",
       "      <td>2024-05-24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9500</th>\n",
       "      <td>EUR/CHF IG Client Sentiment: Our data shows tr...</td>\n",
       "      <td>Sha...</td>\n",
       "      <td>[EUR, CHF]</td>\n",
       "      <td>2024-05-24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9501</th>\n",
       "      <td>A Hawkish Tone from Central Banks Weigh on Sto...</td>\n",
       "      <td>Sha...</td>\n",
       "      <td>[USD]</td>\n",
       "      <td>2024-05-24</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9502 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  Title  \\\n",
       "0     USD/CAD Rate Trades Below 1.3000 Ahead of FOMC...   \n",
       "1                Swiss Franc Forecast: CHF/JPY, NZD/CHF   \n",
       "2     Crude Oil Prices Up as US Strike Kills Iran Qu...   \n",
       "3     Gold Prices Hold Near 4-Month Highs Despite US...   \n",
       "4     US Dollar Prices May Reverse Higher as Japanes...   \n",
       "...                                                 ...   \n",
       "9497  Dow Sustains Losses but Nasdaq 100 Hits New Hi...   \n",
       "9498  US Dollar Technical Outlook: EUR/USD, GBP/USD,...   \n",
       "9499  BoJ Faces Dilemma: Hiking Rates into Economic ...   \n",
       "9500  EUR/CHF IG Client Sentiment: Our data shows tr...   \n",
       "9501  A Hawkish Tone from Central Banks Weigh on Sto...   \n",
       "\n",
       "                                              Full Text  mentioned_currencies  \\\n",
       "0                                                Sha...            [USD, CAD]   \n",
       "1                                                Sha...       [USD, CHF, NZD]   \n",
       "2                                                Sha...  [USD, JPY, AUD, NZD]   \n",
       "3                                                Sha...            [EUR, USD]   \n",
       "4                                                Sha...  [EUR, USD, JPY, GBP]   \n",
       "...                                                 ...                   ...   \n",
       "9497                                             Sha...            [USD, AUD]   \n",
       "9498                                             Sha...  [EUR, USD, GBP, NZD]   \n",
       "9499                                             Sha...            [USD, JPY]   \n",
       "9500                                             Sha...            [EUR, CHF]   \n",
       "9501                                             Sha...                 [USD]   \n",
       "\n",
       "     Trading Date  \n",
       "0      2020-01-01  \n",
       "1      2020-01-02  \n",
       "2      2020-01-02  \n",
       "3      2020-01-02  \n",
       "4      2020-01-02  \n",
       "...           ...  \n",
       "9497   2024-05-23  \n",
       "9498   2024-05-23  \n",
       "9499   2024-05-24  \n",
       "9500   2024-05-24  \n",
       "9501   2024-05-24  \n",
       "\n",
       "[9502 rows x 4 columns]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_news = pd.read_pickle(\"df_news.pkl\")\n",
    "\n",
    "# TODO check if its inclusive\n",
    "df_news = df_news[\n",
    "    (df_news['Date'] >= pd.to_datetime('2020-01-01')) &\n",
    "    (df_news['Date'] < pd.to_datetime('2024-07-01'))\n",
    "]\n",
    "\n",
    "# Reset index\n",
    "df_news = df_news.reset_index(drop=True)\n",
    "\n",
    "# Drop the labels - we will predict these\n",
    "df_news = df_news[['Title', 'Full Text', 'mentioned_currencies', 'Trading Date']]\n",
    "\n",
    "df_news"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c23dc9b6",
   "metadata": {},
   "source": [
    "### 6.2 Load LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40ecafa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to the saved directory\n",
    "model_dir = \"llama_3.1_8B_finetuned\"\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_dir)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_dir).to(device)\n",
    "\n",
    "print(\"tokeniser and model loaded\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62328d40",
   "metadata": {},
   "source": [
    "### 6.3 Make inferences for all articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf4b81c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Getting sentiment predictions for all articles...\")\n",
    "\n",
    "sentiment_predictions = []\n",
    "\n",
    "for idx, row in tqdm(df_news.iterrows(), total=len(df_news), desc=\"Processing articles\"):\n",
    "    sentiment = get_sentiment(row, model, tokenizer)\n",
    "    sentiment_predictions.append(sentiment)\n",
    "    df_news.at[idx, 'sentiment_predictions'] = sentiment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "058f0878",
   "metadata": {},
   "source": [
    "### 6.4 Daily Sentiment Score Generation\n",
    "\n",
    "\n",
    "$$S_{i, t} = round(log(1+CountAppreciation_{i, t}) - log(1+CountDepreciation_{i, t}))$$\n",
    "\n",
    "where $CountAppreciation_{i, t}$ is the number of articles published on day $t$ for which the model assigns the **future label** of currency $i$ to â€œappreciationâ€\n",
    "\n",
    "$round$ function is defined below:\n",
    "$$\n",
    "\\widehat{S}_{i,t} = \n",
    "\\begin{cases} \n",
    "+1, & \\text{if } S_{i,t} > 0, \\\\\n",
    "0, & \\text{if } S_{i,t} = 0, \\\\\n",
    "-1, & \\text{if } S_{i,t} < 0.\n",
    "\\end{cases}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dc32c5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0 -1  1 ... -1  1  1]\n",
      " [ 1  0  0 ... -1  0  1]\n",
      " [-1  0  1 ...  1  0  0]\n",
      " ...\n",
      " [ 0 -1  1 ... -1 -1  0]\n",
      " [ 1 -1  1 ... -1 -1 -1]\n",
      " [ 1  1 -1 ... -1 -1  1]]\n",
      "DatetimeIndex(['2020-01-01', '2020-01-02', '2020-01-03', '2020-01-06',\n",
      "               '2020-01-07', '2020-01-08', '2020-01-09', '2020-01-10',\n",
      "               '2020-01-13', '2020-01-14',\n",
      "               ...\n",
      "               '2024-05-13', '2024-05-14', '2024-05-15', '2024-05-16',\n",
      "               '2024-05-17', '2024-05-20', '2024-05-21', '2024-05-22',\n",
      "               '2024-05-23', '2024-05-24'],\n",
      "              dtype='datetime64[ns]', length=1145, freq=None)\n"
     ]
    }
   ],
   "source": [
    "# Initialise dict (currency, date)\n",
    "data_for_S = {}\n",
    "\n",
    "# Get list of currency codes\n",
    "currency_codes = ['USD', 'EUR', 'JPY', 'GBP', 'CAD', 'AUD', 'CHF', 'SEK', 'NOK', 'NZD']\n",
    "\n",
    "# Group by date\n",
    "for date, group in df_news.groupby('Trading Date'):\n",
    "    # For each currency\n",
    "    for currency in currency_codes:\n",
    "        # Count appreciation and depreciation for this currency on this date\n",
    "        count_appreciation = 0\n",
    "        count_depreciation = 0\n",
    "        \n",
    "        for _, row in group.iterrows():\n",
    "            # Get the future label prediction for this currency\n",
    "            future_key = f'{currency}_future'\n",
    "            prediction = row['sentiment_predictions'].get(future_key, 'unchanged')\n",
    "            \n",
    "            if prediction == 'appreciation':\n",
    "                count_appreciation += 1\n",
    "            elif prediction == 'depreciation':\n",
    "                count_depreciation += 1\n",
    "        \n",
    "        # Calculate S_{i, t} = log(1 + CountAppreciation) - log(1 + CountDepreciation)\n",
    "        S_value = np.log(1 + count_appreciation) - np.log(1 + count_depreciation)\n",
    "\n",
    "        # Round to 1 if positive, 0 if 0, -1 if negative\n",
    "        if S_value > 0:\n",
    "            S_value = 1\n",
    "        elif S_value < 0:\n",
    "            S_value = -1\n",
    "        else:\n",
    "            S_value = 0\n",
    "        \n",
    "        # Add to dict\n",
    "        data_for_S[(currency, date)] = S_value\n",
    "\n",
    "\n",
    "# Get list of dates\n",
    "dates = sorted(set([date for _, date in data_for_S.keys()]))\n",
    "\n",
    "# convert to a numpy matrix shape (currencies, dates)\n",
    "S = np.array([[data_for_S[(currency, date)] for date in dates] for currency in currency_codes])\n",
    "\n",
    "unique_dates_array = np.sort(pd.to_datetime(df_news['Trading Date'].unique()))\n",
    "unique_dates_array = pd.to_datetime(unique_dates_array)\n",
    "unique_dates_array = unique_dates_array.tz_localize(None)  # removes timezone info if present\n",
    "unique_dates_array = unique_dates_array.normalize()        # sets time to midnight (removes time info)\n",
    "\n",
    "print(S)\n",
    "print()\n",
    "print()\n",
    "print(unique_dates_array)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0d2cd40",
   "metadata": {},
   "source": [
    "### 6.5 Get weights\n",
    "\n",
    "$$\n",
    "w_{i,t:t+1} = \n",
    "\\begin{cases} \n",
    "\\frac{\\widehat{S}_{i,t}}{\\sum_{j:\\widehat{S}_{j,t}>0} \\widehat{S}_{j,t}}, & \\text{if } \\widehat{S}_{i,t} > 0 \\text{ and } \\sum_{j:\\widehat{S}_{j,t}>0} \\widehat{S}_{j,t} > 0 \\\\\n",
    "-\\frac{\\widehat{S}_{i,t}}{\\sum_{j:\\widehat{S}_{j,t}<0} |\\widehat{S}_{j,t}|}, & \\text{if } \\widehat{S}_{i,t} < 0 \\text{ and } \\sum_{j:\\widehat{S}_{j,t}<0} |\\widehat{S}_{j,t}| > 0 \\\\\n",
    "0, & \\text{otherwise.}\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "Long on positive sentiment scores\n",
    "\n",
    "Short negative sentiment scores\n",
    "\n",
    "Value of each position is proprtional to sentiment score \n",
    "\n",
    "Value of all short positions are the same as all the long positions for any given day\n",
    "\n",
    "Held for 1 day (close of day t until close of day t+1)\n",
    "\n",
    "if no new article was published on the next day, the previous sentiment signal is retained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "70f28aba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.        , -0.25      ,  0.16666667, ..., -0.16666667,\n",
       "         0.33333333,  0.25      ],\n",
       "       [ 0.25      ,  0.        ,  0.        , ..., -0.16666667,\n",
       "         0.        ,  0.25      ],\n",
       "       [-1.        ,  0.        ,  0.16666667, ...,  1.        ,\n",
       "         0.        ,  0.        ],\n",
       "       ...,\n",
       "       [ 0.        , -0.25      ,  0.16666667, ..., -0.16666667,\n",
       "        -0.25      ,  0.        ],\n",
       "       [ 0.25      , -0.25      ,  0.16666667, ..., -0.16666667,\n",
       "        -0.25      , -0.25      ],\n",
       "       [ 0.25      ,  0.33333333, -0.5       , ..., -0.16666667,\n",
       "        -0.25      ,  0.25      ]], shape=(10, 1145))"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights = np.zeros_like(S, dtype=float)\n",
    "\n",
    "positive_mask = S > 0\n",
    "negative_mask = S < 0\n",
    "\n",
    "sum_positive = np.sum(S * positive_mask, axis=0, keepdims=True)\n",
    "sum_negative_abs = np.sum(np.abs(S) * negative_mask, axis=0, keepdims=True)\n",
    "\n",
    "valid_positive_sums = sum_positive > 0\n",
    "valid_negative_sums = sum_negative_abs > 0\n",
    "\n",
    "with np.errstate(divide='ignore', invalid='ignore'):\n",
    "    positive_weights = np.where(valid_positive_sums, S / sum_positive, 0)\n",
    "    negative_weights = np.where(valid_negative_sums, S / sum_negative_abs, 0)\n",
    "\n",
    "weights = np.where(positive_mask & valid_positive_sums, positive_weights, weights)\n",
    "weights = np.where(negative_mask & valid_negative_sums, negative_weights, weights)\n",
    "\n",
    "weights"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c360eaf",
   "metadata": {},
   "source": [
    "### 6.6 Get the market data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "034c4ee6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1145, 10)\n",
      "1145\n"
     ]
    }
   ],
   "source": [
    "df_log_returns = pd.read_pickle(\"df_log_returns.pkl\")\n",
    "\n",
    "df_log_returns = df_log_returns[df_log_returns.index.isin(unique_dates_array)]\n",
    "\n",
    "print(df_log_returns.shape)\n",
    "print(len(unique_dates_array))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cb6d8a6",
   "metadata": {},
   "source": [
    "### 6.7 Execute strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a206a25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.00089039 -0.00234365 -0.00125497 ... -0.00268306 -0.00329367\n",
      "  0.00029751]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>date</th>\n",
       "      <th>2020-01-01</th>\n",
       "      <th>2020-01-02</th>\n",
       "      <th>2020-01-03</th>\n",
       "      <th>2020-01-06</th>\n",
       "      <th>2020-01-07</th>\n",
       "      <th>2020-01-08</th>\n",
       "      <th>2020-01-09</th>\n",
       "      <th>2020-01-10</th>\n",
       "      <th>2020-01-13</th>\n",
       "      <th>2020-01-14</th>\n",
       "      <th>...</th>\n",
       "      <th>2024-05-13</th>\n",
       "      <th>2024-05-14</th>\n",
       "      <th>2024-05-15</th>\n",
       "      <th>2024-05-16</th>\n",
       "      <th>2024-05-17</th>\n",
       "      <th>2024-05-20</th>\n",
       "      <th>2024-05-21</th>\n",
       "      <th>2024-05-22</th>\n",
       "      <th>2024-05-23</th>\n",
       "      <th>2024-05-24</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>USD</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.002602</td>\n",
       "      <td>0.001598</td>\n",
       "      <td>-0.001798</td>\n",
       "      <td>0.001598</td>\n",
       "      <td>0.002890</td>\n",
       "      <td>0.001492</td>\n",
       "      <td>0.000993</td>\n",
       "      <td>-0.001291</td>\n",
       "      <td>0.000795</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000818</td>\n",
       "      <td>0.000455</td>\n",
       "      <td>-0.004100</td>\n",
       "      <td>-0.002835</td>\n",
       "      <td>0.002561</td>\n",
       "      <td>-0.000731</td>\n",
       "      <td>0.000457</td>\n",
       "      <td>0.002737</td>\n",
       "      <td>-0.001733</td>\n",
       "      <td>0.002370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EUR</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.001632</td>\n",
       "      <td>-0.002043</td>\n",
       "      <td>0.003165</td>\n",
       "      <td>-0.000816</td>\n",
       "      <td>-0.004090</td>\n",
       "      <td>0.001331</td>\n",
       "      <td>-0.001638</td>\n",
       "      <td>0.003887</td>\n",
       "      <td>-0.001430</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000992</td>\n",
       "      <td>0.000594</td>\n",
       "      <td>-0.000099</td>\n",
       "      <td>0.000594</td>\n",
       "      <td>0.000198</td>\n",
       "      <td>0.000693</td>\n",
       "      <td>0.000297</td>\n",
       "      <td>-0.001385</td>\n",
       "      <td>0.000594</td>\n",
       "      <td>0.000297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>JPY</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000407</td>\n",
       "      <td>0.008302</td>\n",
       "      <td>-0.000807</td>\n",
       "      <td>-0.002425</td>\n",
       "      <td>-0.001113</td>\n",
       "      <td>-0.006502</td>\n",
       "      <td>-0.001836</td>\n",
       "      <td>-0.003478</td>\n",
       "      <td>-0.001436</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.001256</td>\n",
       "      <td>-0.003918</td>\n",
       "      <td>0.003219</td>\n",
       "      <td>0.001117</td>\n",
       "      <td>-0.003776</td>\n",
       "      <td>-0.000420</td>\n",
       "      <td>-0.003089</td>\n",
       "      <td>0.000422</td>\n",
       "      <td>-0.001547</td>\n",
       "      <td>-0.002255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GBP</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.002307</td>\n",
       "      <td>-0.004715</td>\n",
       "      <td>0.000289</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.002119</td>\n",
       "      <td>-0.004726</td>\n",
       "      <td>0.005207</td>\n",
       "      <td>-0.010248</td>\n",
       "      <td>0.001262</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000866</td>\n",
       "      <td>0.000769</td>\n",
       "      <td>0.001824</td>\n",
       "      <td>0.000288</td>\n",
       "      <td>0.002011</td>\n",
       "      <td>0.002103</td>\n",
       "      <td>0.001527</td>\n",
       "      <td>0.002666</td>\n",
       "      <td>0.000285</td>\n",
       "      <td>-0.000761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CAD</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000484</td>\n",
       "      <td>0.001933</td>\n",
       "      <td>-0.000097</td>\n",
       "      <td>-0.001160</td>\n",
       "      <td>-0.000871</td>\n",
       "      <td>-0.002616</td>\n",
       "      <td>-0.000971</td>\n",
       "      <td>0.001747</td>\n",
       "      <td>-0.001844</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000596</td>\n",
       "      <td>0.000496</td>\n",
       "      <td>0.001487</td>\n",
       "      <td>-0.000892</td>\n",
       "      <td>0.000496</td>\n",
       "      <td>0.000396</td>\n",
       "      <td>0.000495</td>\n",
       "      <td>-0.003371</td>\n",
       "      <td>0.000199</td>\n",
       "      <td>-0.003083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AUD</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.001670</td>\n",
       "      <td>-0.004038</td>\n",
       "      <td>-0.002569</td>\n",
       "      <td>-0.008945</td>\n",
       "      <td>0.000399</td>\n",
       "      <td>0.000698</td>\n",
       "      <td>0.002689</td>\n",
       "      <td>0.003376</td>\n",
       "      <td>-0.000099</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001907</td>\n",
       "      <td>-0.000858</td>\n",
       "      <td>0.001048</td>\n",
       "      <td>0.001237</td>\n",
       "      <td>0.000951</td>\n",
       "      <td>0.002467</td>\n",
       "      <td>-0.000379</td>\n",
       "      <td>-0.002088</td>\n",
       "      <td>-0.002188</td>\n",
       "      <td>-0.003339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CHF</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.001842</td>\n",
       "      <td>0.001126</td>\n",
       "      <td>0.000511</td>\n",
       "      <td>-0.000409</td>\n",
       "      <td>0.003777</td>\n",
       "      <td>-0.001121</td>\n",
       "      <td>-0.002042</td>\n",
       "      <td>0.002552</td>\n",
       "      <td>0.003765</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000091</td>\n",
       "      <td>-0.001548</td>\n",
       "      <td>0.000273</td>\n",
       "      <td>-0.001823</td>\n",
       "      <td>-0.003565</td>\n",
       "      <td>-0.002200</td>\n",
       "      <td>-0.000184</td>\n",
       "      <td>-0.002942</td>\n",
       "      <td>0.000184</td>\n",
       "      <td>-0.001658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SEK</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.003127</td>\n",
       "      <td>-0.001921</td>\n",
       "      <td>-0.003244</td>\n",
       "      <td>-0.001321</td>\n",
       "      <td>0.001829</td>\n",
       "      <td>-0.001727</td>\n",
       "      <td>-0.002239</td>\n",
       "      <td>0.000509</td>\n",
       "      <td>0.003051</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000886</td>\n",
       "      <td>-0.002328</td>\n",
       "      <td>0.004430</td>\n",
       "      <td>0.005181</td>\n",
       "      <td>-0.003304</td>\n",
       "      <td>0.003743</td>\n",
       "      <td>0.002743</td>\n",
       "      <td>-0.004944</td>\n",
       "      <td>0.003408</td>\n",
       "      <td>-0.000549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NOK</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.002133</td>\n",
       "      <td>0.000648</td>\n",
       "      <td>0.000185</td>\n",
       "      <td>-0.000926</td>\n",
       "      <td>-0.001391</td>\n",
       "      <td>-0.001114</td>\n",
       "      <td>-0.001208</td>\n",
       "      <td>-0.000558</td>\n",
       "      <td>-0.000652</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000106</td>\n",
       "      <td>0.000426</td>\n",
       "      <td>0.001913</td>\n",
       "      <td>-0.000212</td>\n",
       "      <td>0.001486</td>\n",
       "      <td>0.001695</td>\n",
       "      <td>0.002115</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.005583</td>\n",
       "      <td>0.002099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NZD</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.004743</td>\n",
       "      <td>-0.001748</td>\n",
       "      <td>-0.000778</td>\n",
       "      <td>-0.001363</td>\n",
       "      <td>0.002723</td>\n",
       "      <td>-0.002821</td>\n",
       "      <td>-0.000097</td>\n",
       "      <td>0.001849</td>\n",
       "      <td>-0.002531</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000495</td>\n",
       "      <td>0.000297</td>\n",
       "      <td>0.003655</td>\n",
       "      <td>0.003740</td>\n",
       "      <td>0.002649</td>\n",
       "      <td>-0.000882</td>\n",
       "      <td>-0.001177</td>\n",
       "      <td>0.004017</td>\n",
       "      <td>0.002442</td>\n",
       "      <td>-0.001367</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows Ã— 1145 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "date  2020-01-01  2020-01-02  2020-01-03  2020-01-06  2020-01-07  2020-01-08  \\\n",
       "USD          0.0    0.002602    0.001598   -0.001798    0.001598    0.002890   \n",
       "EUR          0.0   -0.001632   -0.002043    0.003165   -0.000816   -0.004090   \n",
       "JPY          0.0    0.000407    0.008302   -0.000807   -0.002425   -0.001113   \n",
       "GBP          0.0    0.002307   -0.004715    0.000289    0.000000    0.002119   \n",
       "CAD          0.0    0.000484    0.001933   -0.000097   -0.001160   -0.000871   \n",
       "AUD          0.0   -0.001670   -0.004038   -0.002569   -0.008945    0.000399   \n",
       "CHF          0.0   -0.001842    0.001126    0.000511   -0.000409    0.003777   \n",
       "SEK          0.0   -0.003127   -0.001921   -0.003244   -0.001321    0.001829   \n",
       "NOK          0.0    0.002133    0.000648    0.000185   -0.000926   -0.001391   \n",
       "NZD          0.0   -0.004743   -0.001748   -0.000778   -0.001363    0.002723   \n",
       "\n",
       "date  2020-01-09  2020-01-10  2020-01-13  2020-01-14  ...  2024-05-13  \\\n",
       "USD     0.001492    0.000993   -0.001291    0.000795  ...   -0.000818   \n",
       "EUR     0.001331   -0.001638    0.003887   -0.001430  ...    0.000992   \n",
       "JPY    -0.006502   -0.001836   -0.003478   -0.001436  ...   -0.001256   \n",
       "GBP    -0.004726    0.005207   -0.010248    0.001262  ...    0.000866   \n",
       "CAD    -0.002616   -0.000971    0.001747   -0.001844  ...    0.000596   \n",
       "AUD     0.000698    0.002689    0.003376   -0.000099  ...    0.001907   \n",
       "CHF    -0.001121   -0.002042    0.002552    0.003765  ...   -0.000091   \n",
       "SEK    -0.001727   -0.002239    0.000509    0.003051  ...   -0.000886   \n",
       "NOK    -0.001114   -0.001208   -0.000558   -0.000652  ...   -0.000106   \n",
       "NZD    -0.002821   -0.000097    0.001849   -0.002531  ...    0.000495   \n",
       "\n",
       "date  2024-05-14  2024-05-15  2024-05-16  2024-05-17  2024-05-20  2024-05-21  \\\n",
       "USD     0.000455   -0.004100   -0.002835    0.002561   -0.000731    0.000457   \n",
       "EUR     0.000594   -0.000099    0.000594    0.000198    0.000693    0.000297   \n",
       "JPY    -0.003918    0.003219    0.001117   -0.003776   -0.000420   -0.003089   \n",
       "GBP     0.000769    0.001824    0.000288    0.002011    0.002103    0.001527   \n",
       "CAD     0.000496    0.001487   -0.000892    0.000496    0.000396    0.000495   \n",
       "AUD    -0.000858    0.001048    0.001237    0.000951    0.002467   -0.000379   \n",
       "CHF    -0.001548    0.000273   -0.001823   -0.003565   -0.002200   -0.000184   \n",
       "SEK    -0.002328    0.004430    0.005181   -0.003304    0.003743    0.002743   \n",
       "NOK     0.000426    0.001913   -0.000212    0.001486    0.001695    0.002115   \n",
       "NZD     0.000297    0.003655    0.003740    0.002649   -0.000882   -0.001177   \n",
       "\n",
       "date  2024-05-22  2024-05-23  2024-05-24  \n",
       "USD     0.002737   -0.001733    0.002370  \n",
       "EUR    -0.001385    0.000594    0.000297  \n",
       "JPY     0.000422   -0.001547   -0.002255  \n",
       "GBP     0.002666    0.000285   -0.000761  \n",
       "CAD    -0.003371    0.000199   -0.003083  \n",
       "AUD    -0.002088   -0.002188   -0.003339  \n",
       "CHF    -0.002942    0.000184   -0.001658  \n",
       "SEK    -0.004944    0.003408   -0.000549  \n",
       "NOK     0.000000    0.005583    0.002099  \n",
       "NZD     0.004017    0.002442   -0.001367  \n",
       "\n",
       "[10 rows x 1145 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_log_returns_T = df_log_returns.transpose()\n",
    "log_returns = df_log_returns_T.values   # turn it into a matrix\n",
    "\n",
    "# Remove the last one as doesnt have future returns\n",
    "W_active = weights[:, :-1]\n",
    "\n",
    "# Allign for future returns\n",
    "R_future = log_returns[:, 1:]\n",
    "\n",
    "# Element wise multiplication\n",
    "# Sum vertically for each day\n",
    "daily_pnl = np.sum(W_active * R_future, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "114f5c32",
   "metadata": {},
   "source": [
    "### 6.8 Evaluate results\n",
    "\n",
    "Assume a zero cost portiolio so risk free rate is 0 \n",
    "\n",
    "$$Annualized\\ Return = mean\\ daily\\ return \\times 252$$\n",
    "\n",
    "$$Annualized\\ Volatility = Standard\\ Deviation\\ of\\ Daily\\ Returns \\times sqrt(252)$$\n",
    "\n",
    "$$Sharpe\\ Ratio = \\frac{Annualized\\ Return}{Annualized\\ Volatility}$$\n",
    "\n",
    "$$Maximum\\ Drawdown =\\ The\\ largest\\ peak\\ to\\ trough\\ decline\\ in\\ cumulative\\ returns$$\n",
    "\n",
    "$$Transaction\\ Costs = sum\\ of\\ absolute\\ weight\\ changes\\ per\\ day,\\ averaged,\\ then\\ annualized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "53fde5b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Annualized Return:    -1.04%\n",
      "Annualized Volatility:5.07%\n",
      "Sharpe Ratio:         -0.21\n",
      "Max Drawdown:         9.39%\n",
      "Rebalancing Freq:     678.25\n"
     ]
    }
   ],
   "source": [
    "ANNUALIZATION_FACTOR = 252    # Number of trading days per year\n",
    "\n",
    "\n",
    "# Annualized Return\n",
    "ann_return = np.mean(daily_pnl) * ANNUALIZATION_FACTOR\n",
    "ann_return_pc = ann_return * 100  # percent\n",
    "\n",
    "# Annualized Volatility\n",
    "ann_vol = np.std(daily_pnl, ddof=1) * np.sqrt(ANNUALIZATION_FACTOR)\n",
    "ann_vol_pc = ann_vol * 100        # Convert to percentage\n",
    "\n",
    "# Sharpe Ratio\n",
    "if ann_vol != 0:\n",
    "    sharpe_ratio = ann_return / ann_vol\n",
    "else:\n",
    "    sharpe_ratio = 0.0\n",
    "\n",
    "# Maximum Drawdown\n",
    "cumulative_returns = np.cumsum(daily_pnl)\n",
    "running_max = np.maximum.accumulate(cumulative_returns)\n",
    "drawdown = running_max - cumulative_returns\n",
    "max_drawdown = np.max(drawdown)\n",
    "max_drawdown_pc = max_drawdown * 100  # Convert to percentage\n",
    "\n",
    "# Transaction Costs (Rebalancing Frequency)\n",
    "weight_changes = np.abs(np.diff(weights, axis=1))  # Change from day t to t+1\n",
    "daily_turnover = np.sum(weight_changes, axis=0)    # Total turnover per day\n",
    "rebalancing_frequency = np.mean(daily_turnover) * ANNUALIZATION_FACTOR\n",
    "\n",
    "print(f\"Annualized Return:    {ann_return_pc:.2f}%\")\n",
    "print(f\"Annualized Volatility:{ann_vol_pc:.2f}%\")\n",
    "print(f\"Sharpe Ratio:         {sharpe_ratio:.2f}\")\n",
    "print(f\"Max Drawdown:         {max_drawdown_pc:.2f}%\")\n",
    "print(f\"Rebalancing Freq:     {rebalancing_frequency:.2f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
