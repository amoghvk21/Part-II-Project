W0215 07:37:23.921000 6425 torch/distributed/run.py:793] 
W0215 07:37:23.921000 6425 torch/distributed/run.py:793] *****************************************
W0215 07:37:23.921000 6425 torch/distributed/run.py:793] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
W0215 07:37:23.921000 6425 torch/distributed/run.py:793] *****************************************
imports done
imports done
imports done
imports done
DDP initialized: local_rank=0, rank=0, world_size=4
Reading from cache
new hyperparams
Size of train set:  23840
Size of test set:  5960
Size of eval set:  200
new hyperparams
Note: Environment variable`HF_TOKEN` is set and is the current active token independently from the token you've just configured.
PID=6476 RANK=1 LOCAL_RANK=1 
new hyperparams
Note: Environment variable`HF_TOKEN` is set and is the current active token independently from the token you've just configured.
DDP enabled | world_size=4
PID=6475 RANK=0 LOCAL_RANK=0 
Note: Environment variable`HF_TOKEN` is set and is the current active token independently from the token you've just configured.
PID=6477 RANK=2 LOCAL_RANK=2 
DEBUG: Rank 1 is attempting to load model.
DEBUG: Rank 1 device_map is STRICTLY: {'': 1}
Set pad_token to Llama 3 reserved token (<|reserved_special_token_0|>)
DEBUG: Rank 0 is attempting to load model.
DEBUG: Rank 0 device_map is STRICTLY: {'': 0}
DEBUG: Rank 2 is attempting to load model.
DEBUG: Rank 2 device_map is STRICTLY: {'': 2}
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:03<00:10,  3.38s/it]Loading checkpoint shards:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:03<00:10,  3.36s/it]Loading checkpoint shards:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:03<00:10,  3.40s/it]Loading checkpoint shards:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:07<00:07,  3.80s/it]Loading checkpoint shards:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:07<00:07,  3.78s/it]Loading checkpoint shards:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:07<00:07,  3.79s/it]Loading checkpoint shards:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:11<00:03,  3.90s/it]Loading checkpoint shards:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:11<00:03,  3.88s/it]Loading checkpoint shards:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:11<00:03,  3.90s/it]Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:11<00:00,  2.45s/it]Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:11<00:00,  2.93s/it]
Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:11<00:00,  2.44s/it]Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:11<00:00,  2.92s/it]
[Rank 1] Model loaded on device: cuda:1
Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:11<00:00,  2.45s/it]Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:11<00:00,  2.93s/it]
[Rank 2] Model loaded on device: cuda:2
[Rank 0] Model loaded on device: cuda:0
setup complete
Number of GPUs available: 4
GPU 0: NVIDIA L40S
GPU 1: NVIDIA L40S
GPU 2: NVIDIA L40S
GPU 3: NVIDIA L40S
finetuning model | learning_rate=2e-05 | save_dir=finetuned_llama_8b_lr2e5
Training with DDP | world_size=4
wandb: [wandb.login()] Loaded credentials for https://api.wandb.ai from WANDB_API_KEY.
wandb: Currently logged in as: av670 (av670-university-of-cambridge) to https://api.wandb.ai. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.24.2
wandb: Run data is saved locally in /home/ubuntu/Part-II-Project/wandb/run-20260215_073743-tbrn1mcq
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run finetuned_llama_8b_lr2e5
wandb: â­ï¸ View project at https://wandb.ai/av670-university-of-cambridge/part-ii-project
wandb: ðŸš€ View run at https://wandb.ai/av670-university-of-cambridge/part-ii-project/runs/tbrn1mcq
Applying formatting function to train dataset:   0%|          | 0/23840 [00:00<?, ? examples/s]Applying formatting function to train dataset:   1%|â–         | 341/23840 [00:00<00:07, 3347.77 examples/s]Applying formatting function to train dataset:   3%|â–Ž         | 745/23840 [00:00<00:06, 3746.61 examples/s]Applying formatting function to train dataset:   5%|â–Œ         | 1204/23840 [00:00<00:07, 2958.10 examples/s]Applying formatting function to train dataset:   7%|â–‹         | 1616/23840 [00:00<00:06, 3322.95 examples/s]Applying formatting function to train dataset:   8%|â–Š         | 2000/23840 [00:00<00:07, 2908.51 examples/s]Applying formatting function to train dataset:  10%|â–ˆ         | 2415/23840 [00:00<00:06, 3242.82 examples/s]Applying formatting function to train dataset:  12%|â–ˆâ–        | 2829/23840 [00:00<00:06, 3490.30 examples/s]Applying formatting function to train dataset:  13%|â–ˆâ–Ž        | 3206/23840 [00:01<00:06, 3121.53 examples/s]Applying formatting function to train dataset:  15%|â–ˆâ–Œ        | 3619/23840 [00:01<00:05, 3384.55 examples/s]Applying formatting function to train dataset:  17%|â–ˆâ–‹        | 4000/23840 [00:01<00:06, 2917.22 examples/s]Applying formatting function to train dataset:  19%|â–ˆâ–‰        | 4493/23840 [00:01<00:08, 2211.44 examples/s]Applying formatting function to train dataset:  21%|â–ˆâ–ˆ        | 4902/23840 [00:01<00:07, 2558.66 examples/s]Applying formatting function to train dataset:  23%|â–ˆâ–ˆâ–Ž       | 5415/23840 [00:01<00:06, 2639.26 examples/s]Applying formatting function to train dataset:  24%|â–ˆâ–ˆâ–       | 5828/23840 [00:01<00:06, 2940.62 examples/s]Applying formatting function to train dataset:  26%|â–ˆâ–ˆâ–Œ       | 6204/23840 [00:02<00:06, 2798.89 examples/s]Applying formatting function to train dataset:  28%|â–ˆâ–ˆâ–Š       | 6619/23840 [00:02<00:05, 3098.32 examples/s]Applying formatting function to train dataset:  29%|â–ˆâ–ˆâ–‰       | 7000/23840 [00:02<00:05, 2902.73 examples/s]Applying formatting function to train dataset:  31%|â–ˆâ–ˆâ–ˆ       | 7411/23840 [00:02<00:05, 3184.26 examples/s]Applying formatting function to train dataset:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 7825/23840 [00:02<00:04, 3423.19 examples/s]Applying formatting function to train dataset:  34%|â–ˆâ–ˆâ–ˆâ–      | 8203/23840 [00:02<00:05, 2808.35 examples/s]Applying formatting function to train dataset:  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 8616/23840 [00:02<00:04, 3111.64 examples/s]Applying formatting function to train dataset:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 9000/23840 [00:03<00:05, 2914.07 examples/s]Applying formatting function to train dataset:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 9409/23840 [00:03<00:04, 3193.81 examples/s]Applying formatting function to train dataset:  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 9823/23840 [00:03<00:04, 3432.74 examples/s]Applying formatting function to train dataset:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 10203/23840 [00:03<00:06, 2077.52 examples/s]Applying formatting function to train dataset:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 10615/23840 [00:03<00:05, 2450.81 examples/s]Applying formatting function to train dataset:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 11000/23840 [00:03<00:05, 2474.41 examples/s]Applying formatting function to train dataset:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 11414/23840 [00:03<00:04, 2824.63 examples/s]Applying formatting function to train dataset:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 11826/23840 [00:04<00:03, 3123.42 examples/s]Applying formatting function to train dataset:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 12205/23840 [00:04<00:03, 2918.98 examples/s]Applying formatting function to train dataset:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 12620/23840 [00:04<00:03, 3211.89 examples/s]Applying formatting function to train dataset:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 13000/23840 [00:04<00:03, 2969.32 examples/s]Applying formatting function to train dataset:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 13409/23840 [00:04<00:03, 3240.87 examples/s]Applying formatting function to train dataset:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 13826/23840 [00:04<00:02, 3477.32 examples/s]Applying formatting function to train dataset:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 14208/23840 [00:04<00:03, 3134.50 examples/s]Applying formatting function to train dataset:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 14624/23840 [00:04<00:02, 3390.96 examples/s]Applying formatting function to train dataset:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 15000/23840 [00:05<00:03, 2565.07 examples/s]Applying formatting function to train dataset:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 15410/23840 [00:05<00:02, 2897.67 examples/s]Applying formatting function to train dataset:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 15827/23840 [00:05<00:02, 3197.75 examples/s]Applying formatting function to train dataset:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 16207/23840 [00:05<00:03, 2013.47 examples/s]Applying formatting function to train dataset:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 16620/23840 [00:05<00:03, 2389.65 examples/s]Applying formatting function to train dataset:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 17000/23840 [00:05<00:02, 2418.50 examples/s]Applying formatting function to train dataset:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 17410/23840 [00:06<00:02, 2767.00 examples/s]Applying formatting function to train dataset:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 17824/23840 [00:06<00:01, 3078.34 examples/s]Applying formatting function to train dataset:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 18204/23840 [00:06<00:01, 2879.88 examples/s]Applying formatting function to train dataset:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 18617/23840 [00:06<00:01, 3173.68 examples/s]Applying formatting function to train dataset:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 19000/23840 [00:06<00:01, 2936.64 examples/s]Applying formatting function to train dataset:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 19409/23840 [00:06<00:01, 3211.82 examples/s]Applying formatting function to train dataset:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 19822/23840 [00:06<00:01, 3445.74 examples/s]Applying formatting function to train dataset:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 20206/23840 [00:06<00:01, 3110.69 examples/s]Applying formatting function to train dataset:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 20620/23840 [00:07<00:00, 3366.43 examples/s]Applying formatting function to train dataset:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 21000/23840 [00:07<00:00, 3053.85 examples/s]Applying formatting function to train dataset:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 21408/23840 [00:07<00:00, 3307.35 examples/s]Applying formatting function to train dataset:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 21821/23840 [00:07<00:00, 3521.74 examples/s]Applying formatting function to train dataset:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 22202/23840 [00:07<00:00, 2086.24 examples/s]Applying formatting function to train dataset:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 22614/23840 [00:07<00:00, 2458.33 examples/s]Applying formatting function to train dataset:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 23000/23840 [00:07<00:00, 2460.00 examples/s]Applying formatting function to train dataset:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 23401/23840 [00:08<00:00, 2783.98 examples/s]Applying formatting function to train dataset: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 23805/23840 [00:08<00:00, 3072.55 examples/s]Applying formatting function to train dataset: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 23840/23840 [00:08<00:00, 2886.17 examples/s]
Adding EOS to train dataset:   0%|          | 0/23840 [00:00<?, ? examples/s]Adding EOS to train dataset:   2%|â–         | 518/23840 [00:00<00:04, 5099.63 examples/s]Adding EOS to train dataset:   5%|â–Œ         | 1258/23840 [00:00<00:05, 4463.64 examples/s]Adding EOS to train dataset:   7%|â–‹         | 1768/23840 [00:00<00:04, 4695.92 examples/s]Adding EOS to train dataset:   9%|â–‰         | 2258/23840 [00:00<00:05, 4226.52 examples/s]Adding EOS to train dataset:  12%|â–ˆâ–        | 2773/23840 [00:00<00:04, 4503.56 examples/s]Adding EOS to train dataset:  14%|â–ˆâ–Ž        | 3257/23840 [00:00<00:04, 4262.19 examples/s]Adding EOS to train dataset:  16%|â–ˆâ–Œ        | 3771/23840 [00:00<00:04, 4509.24 examples/s]Adding EOS to train dataset:  18%|â–ˆâ–Š        | 4255/23840 [00:00<00:04, 4030.16 examples/s]Adding EOS to train dataset:  20%|â–ˆâ–ˆ        | 4768/23840 [00:01<00:04, 4318.53 examples/s]Adding EOS to train dataset:  22%|â–ˆâ–ˆâ–       | 5259/23840 [00:01<00:04, 4176.17 examples/s]Adding EOS to train dataset:  24%|â–ˆâ–ˆâ–       | 5769/23840 [00:01<00:04, 4419.60 examples/s]Adding EOS to train dataset:  26%|â–ˆâ–ˆâ–‹       | 6258/23840 [00:01<00:04, 4239.56 examples/s]Adding EOS to train dataset:  28%|â–ˆâ–ˆâ–Š       | 6774/23840 [00:01<00:03, 4483.55 examples/s]Adding EOS to train dataset:  30%|â–ˆâ–ˆâ–ˆ       | 7259/23840 [00:01<00:03, 4276.67 examples/s]Adding EOS to train dataset:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 7771/23840 [00:01<00:03, 4502.06 examples/s]Adding EOS to train dataset:  35%|â–ˆâ–ˆâ–ˆâ–      | 8255/23840 [00:01<00:04, 3859.52 examples/s]Adding EOS to train dataset:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 8765/23840 [00:02<00:03, 4168.62 examples/s]Adding EOS to train dataset:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 9261/23840 [00:02<00:03, 4079.74 examples/s]Adding EOS to train dataset:  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 9776/23840 [00:02<00:03, 4355.76 examples/s]Adding EOS to train dataset:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 10260/23840 [00:02<00:03, 4202.60 examples/s]Adding EOS to train dataset:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 10773/23840 [00:02<00:02, 4447.22 examples/s]Adding EOS to train dataset:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 11257/23840 [00:02<00:02, 4242.13 examples/s]Adding EOS to train dataset:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 11768/23840 [00:02<00:02, 4471.65 examples/s]Adding EOS to train dataset:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 12258/23840 [00:02<00:02, 4268.17 examples/s]Adding EOS to train dataset:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 12771/23840 [00:02<00:02, 4496.97 examples/s]Adding EOS to train dataset:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 13256/23840 [00:03<00:02, 4270.66 examples/s]Adding EOS to train dataset:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 13766/23840 [00:03<00:02, 4491.83 examples/s]Adding EOS to train dataset:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 14258/23840 [00:03<00:02, 4275.72 examples/s]Adding EOS to train dataset:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 14771/23840 [00:03<00:02, 4503.01 examples/s]Adding EOS to train dataset:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 15257/23840 [00:03<00:02, 3543.20 examples/s]Adding EOS to train dataset:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 15770/23840 [00:03<00:02, 3911.33 examples/s]Adding EOS to train dataset:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 16258/23840 [00:03<00:01, 3896.53 examples/s]Adding EOS to train dataset:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 16769/23840 [00:03<00:01, 4198.55 examples/s]Adding EOS to train dataset:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 17256/23840 [00:04<00:01, 4086.18 examples/s]Adding EOS to train dataset:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 17763/23840 [00:04<00:01, 4340.51 examples/s]Adding EOS to train dataset:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 18256/23840 [00:04<00:01, 4182.08 examples/s]Adding EOS to train dataset:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 18768/23840 [00:04<00:01, 4427.89 examples/s]Adding EOS to train dataset:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 19257/23840 [00:04<00:01, 4246.78 examples/s]Adding EOS to train dataset:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 19772/23840 [00:04<00:00, 4485.77 examples/s]Adding EOS to train dataset:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 20258/23840 [00:04<00:00, 4277.33 examples/s]Adding EOS to train dataset:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 20770/23840 [00:04<00:00, 4501.76 examples/s]Adding EOS to train dataset:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 21257/23840 [00:04<00:00, 4288.68 examples/s]Adding EOS to train dataset:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 21772/23840 [00:05<00:00, 4518.93 examples/s]Adding EOS to train dataset:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 22262/23840 [00:05<00:00, 4312.27 examples/s]Adding EOS to train dataset:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 22783/23840 [00:05<00:00, 4552.08 examples/s]Adding EOS to train dataset:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 23261/23840 [00:05<00:00, 4315.60 examples/s]Adding EOS to train dataset: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 23785/23840 [00:05<00:00, 4562.46 examples/s]Adding EOS to train dataset: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 23840/23840 [00:05<00:00, 4282.36 examples/s]
Tokenizing train dataset:   0%|          | 0/23840 [00:00<?, ? examples/s]Tokenizing train dataset:   0%|          | 44/23840 [00:00<00:56, 424.00 examples/s]Tokenizing train dataset:   0%|          | 95/23840 [00:00<00:50, 466.03 examples/s]Tokenizing train dataset:   1%|          | 142/23840 [00:00<00:50, 465.28 examples/s]Tokenizing train dataset:   1%|          | 194/23840 [00:00<00:48, 482.95 examples/s]Tokenizing train dataset:   1%|          | 247/23840 [00:00<00:47, 495.06 examples/s]Tokenizing train dataset:   1%|          | 297/23840 [00:00<00:47, 491.46 examples/s]Tokenizing train dataset:   1%|â–         | 347/23840 [00:00<00:47, 491.09 examples/s]Tokenizing train dataset:   2%|â–         | 421/23840 [00:00<00:47, 491.64 examples/s]Tokenizing train dataset:   2%|â–         | 471/23840 [00:00<00:47, 490.65 examples/s]W0215 07:38:00.869000 6425 torch/distributed/elastic/multiprocessing/api.py:897] Sending process 6475 closing signal SIGTERM
W0215 07:38:00.870000 6425 torch/distributed/elastic/multiprocessing/api.py:897] Sending process 6476 closing signal SIGTERM
W0215 07:38:00.871000 6425 torch/distributed/elastic/multiprocessing/api.py:897] Sending process 6477 closing signal SIGTERM
E0215 07:38:01.348000 6425 torch/distributed/elastic/multiprocessing/api.py:869] failed (exitcode: -11) local_rank: 3 (pid: 6478) of binary: /home/ubuntu/Part-II-Project/venv/bin/python3.12
Traceback (most recent call last):
  File "/home/ubuntu/Part-II-Project/venv/bin/torchrun", line 8, in <module>
    sys.exit(main())
             ^^^^^^
  File "/home/ubuntu/Part-II-Project/venv/lib/python3.12/site-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py", line 355, in wrapper
    return f(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/Part-II-Project/venv/lib/python3.12/site-packages/torch/distributed/run.py", line 919, in main
    run(args)
  File "/home/ubuntu/Part-II-Project/venv/lib/python3.12/site-packages/torch/distributed/run.py", line 910, in run
    elastic_launch(
  File "/home/ubuntu/Part-II-Project/venv/lib/python3.12/site-packages/torch/distributed/launcher/api.py", line 138, in __call__
    return launch_agent(self._config, self._entrypoint, list(args))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/Part-II-Project/venv/lib/python3.12/site-packages/torch/distributed/launcher/api.py", line 269, in launch_agent
    raise ChildFailedError(
torch.distributed.elastic.multiprocessing.errors.ChildFailedError: 
======================================================
_2_llm_paper/ddp_finetune_llama_job.py FAILED
------------------------------------------------------
Failures:
  <NO_OTHER_FAILURES>
------------------------------------------------------
Root Cause (first observed failure):
[0]:
  time      : 2026-02-15_07:38:00
  host      : ip-172-31-82-239.ec2.internal
  rank      : 3 (local_rank: 3)
  exitcode  : -11 (pid: 6478)
  error_file: <N/A>
  traceback : Signal 11 (SIGSEGV) received by PID 6478
======================================================
