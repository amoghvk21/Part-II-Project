Note: Environment variable`HF_TOKEN` is set and is the current active token independently from the token you've just configured.
imports done
Reading from cache
Size of train set:  23840
Size of test set:  5960
Size of eval set:  200
new hyperparams
Set pad_token to Llama 3 reserved token (<|reserved_special_token_0|>)
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:40<02:01, 40.52s/it]Loading checkpoint shards:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [01:18<01:18, 39.11s/it]Loading checkpoint shards:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [01:56<00:38, 38.37s/it]Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [02:04<00:00, 26.70s/it]Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [02:04<00:00, 31.23s/it]
wandb: [wandb.login()] Loaded credentials for https://api.wandb.ai from WANDB_API_KEY.
wandb: Currently logged in as: av670 (av670-university-of-cambridge) to https://api.wandb.ai. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.24.2
wandb: Run data is saved locally in /home/ubuntu/Part-II-Project/wandb/run-20260214_210936-27vxjalm
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run finetuned_llama_8b
wandb: â­ï¸ View project at https://wandb.ai/av670-university-of-cambridge/part-ii-project
wandb: ðŸš€ View run at https://wandb.ai/av670-university-of-cambridge/part-ii-project/runs/27vxjalm
Model loaded with device_map='auto'. First parameter on: cuda:1
setup complete
Number of GPUs available: 4
GPU 0: NVIDIA L40S
GPU 1: NVIDIA L40S
GPU 2: NVIDIA L40S
GPU 3: NVIDIA L40S
finetuning model
Applying formatting function to train dataset:   0%|          | 0/23840 [00:00<?, ? examples/s]Applying formatting function to train dataset:   1%|â–         | 342/23840 [00:00<00:07, 3356.64 examples/s]Applying formatting function to train dataset:   3%|â–Ž         | 744/23840 [00:00<00:06, 3740.35 examples/s]Applying formatting function to train dataset:   5%|â–Œ         | 1210/23840 [00:00<00:07, 3064.60 examples/s]Applying formatting function to train dataset:   7%|â–‹         | 1625/23840 [00:00<00:06, 3414.10 examples/s]Applying formatting function to train dataset:   8%|â–Š         | 2000/23840 [00:00<00:07, 2974.74 examples/s]Applying formatting function to train dataset:  10%|â–ˆ         | 2417/23840 [00:00<00:06, 3303.04 examples/s]Applying formatting function to train dataset:  12%|â–ˆâ–        | 2843/23840 [00:00<00:05, 3571.24 examples/s]Applying formatting function to train dataset:  14%|â–ˆâ–        | 3424/23840 [00:01<00:06, 3316.72 examples/s]Applying formatting function to train dataset:  16%|â–ˆâ–Œ        | 3846/23840 [00:01<00:05, 3535.92 examples/s]Applying formatting function to train dataset:  18%|â–ˆâ–Š        | 4408/23840 [00:01<00:08, 2231.25 examples/s]Applying formatting function to train dataset:  20%|â–ˆâ–ˆ        | 4816/23840 [00:01<00:07, 2541.53 examples/s]Applying formatting function to train dataset:  22%|â–ˆâ–ˆâ–       | 5208/23840 [00:01<00:07, 2558.22 examples/s]Applying formatting function to train dataset:  24%|â–ˆâ–ˆâ–Ž       | 5621/23840 [00:01<00:06, 2873.61 examples/s]Applying formatting function to train dataset:  25%|â–ˆâ–ˆâ–Œ       | 6000/23840 [00:02<00:06, 2767.82 examples/s]Applying formatting function to train dataset:  27%|â–ˆâ–ˆâ–‹       | 6414/23840 [00:02<00:05, 3072.87 examples/s]Applying formatting function to train dataset:  29%|â–ˆâ–ˆâ–Š       | 6828/23840 [00:02<00:05, 3329.58 examples/s]Applying formatting function to train dataset:  30%|â–ˆâ–ˆâ–ˆ       | 7207/23840 [00:02<00:05, 3052.88 examples/s]Applying formatting function to train dataset:  32%|â–ˆâ–ˆâ–ˆâ–      | 7621/23840 [00:02<00:04, 3316.95 examples/s]Applying formatting function to train dataset:  34%|â–ˆâ–ˆâ–ˆâ–Ž      | 8000/23840 [00:02<00:05, 2789.34 examples/s]Applying formatting function to train dataset:  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 8414/23840 [00:02<00:04, 3100.79 examples/s]Applying formatting function to train dataset:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 8830/23840 [00:02<00:04, 3362.54 examples/s]Applying formatting function to train dataset:  39%|â–ˆâ–ˆâ–ˆâ–Š      | 9208/23840 [00:03<00:04, 3087.65 examples/s]Applying formatting function to train dataset:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 9624/23840 [00:03<00:04, 3352.45 examples/s]Applying formatting function to train dataset:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 10000/23840 [00:03<00:06, 2069.24 examples/s]Applying formatting function to train dataset:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 10408/23840 [00:03<00:05, 2436.92 examples/s]Applying formatting function to train dataset:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 10821/23840 [00:03<00:04, 2786.50 examples/s]Applying formatting function to train dataset:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 11208/23840 [00:03<00:04, 2700.56 examples/s]Applying formatting function to train dataset:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 11617/23840 [00:03<00:04, 3012.51 examples/s]Applying formatting function to train dataset:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 12000/23840 [00:04<00:04, 2841.17 examples/s]Applying formatting function to train dataset:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 12409/23840 [00:04<00:03, 3132.63 examples/s]Applying formatting function to train dataset:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 12818/23840 [00:04<00:03, 3373.05 examples/s]Applying formatting function to train dataset:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 13206/23840 [00:04<00:03, 3066.41 examples/s]Applying formatting function to train dataset:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 13621/23840 [00:04<00:03, 3333.57 examples/s]Applying formatting function to train dataset:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 14000/23840 [00:04<00:03, 3066.97 examples/s]Applying formatting function to train dataset:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 14415/23840 [00:04<00:02, 3335.82 examples/s]Applying formatting function to train dataset:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 14832/23840 [00:04<00:02, 3552.26 examples/s]Applying formatting function to train dataset:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 15211/23840 [00:05<00:03, 2668.15 examples/s]Applying formatting function to train dataset:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 15627/23840 [00:05<00:02, 2998.62 examples/s]Applying formatting function to train dataset:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 16000/23840 [00:05<00:04, 1956.24 examples/s]Applying formatting function to train dataset:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 16403/23840 [00:05<00:03, 2319.11 examples/s]Applying formatting function to train dataset:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 16814/23840 [00:05<00:02, 2676.06 examples/s]Applying formatting function to train dataset:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 17206/23840 [00:05<00:02, 2640.74 examples/s]Applying formatting function to train dataset:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 17621/23840 [00:06<00:02, 2973.65 examples/s]Applying formatting function to train dataset:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 18000/23840 [00:06<00:02, 2833.65 examples/s]Applying formatting function to train dataset:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 18414/23840 [00:06<00:01, 3139.41 examples/s]Applying formatting function to train dataset:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 18829/23840 [00:06<00:01, 3391.59 examples/s]Applying formatting function to train dataset:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 19205/23840 [00:06<00:01, 3086.94 examples/s]Applying formatting function to train dataset:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 19618/23840 [00:06<00:01, 3345.73 examples/s]Applying formatting function to train dataset:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 20000/23840 [00:06<00:01, 3067.19 examples/s]Applying formatting function to train dataset:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 20408/23840 [00:06<00:01, 3318.32 examples/s]Applying formatting function to train dataset:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 20822/23840 [00:07<00:00, 3531.43 examples/s]Applying formatting function to train dataset:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 21208/23840 [00:07<00:00, 3178.33 examples/s]Applying formatting function to train dataset:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 21627/23840 [00:07<00:00, 3433.55 examples/s]Applying formatting function to train dataset:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 22000/23840 [00:07<00:00, 2092.42 examples/s]Applying formatting function to train dataset:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 22414/23840 [00:07<00:00, 2469.73 examples/s]Applying formatting function to train dataset:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 22826/23840 [00:07<00:00, 2812.45 examples/s]Applying formatting function to train dataset:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 23204/23840 [00:07<00:00, 2718.44 examples/s]Applying formatting function to train dataset:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 23613/23840 [00:08<00:00, 3028.07 examples/s]Applying formatting function to train dataset: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 23840/23840 [00:08<00:00, 2918.51 examples/s]
Adding EOS to train dataset:   0%|          | 0/23840 [00:00<?, ? examples/s]Adding EOS to train dataset:   2%|â–         | 524/23840 [00:00<00:04, 5165.25 examples/s]Adding EOS to train dataset:   5%|â–Œ         | 1264/23840 [00:00<00:05, 4463.72 examples/s]Adding EOS to train dataset:   8%|â–Š         | 1798/23840 [00:00<00:04, 4779.18 examples/s]Adding EOS to train dataset:  11%|â–ˆ         | 2535/23840 [00:00<00:04, 4484.59 examples/s]Adding EOS to train dataset:  13%|â–ˆâ–Ž        | 3000/23840 [00:00<00:04, 4294.79 examples/s]Adding EOS to train dataset:  15%|â–ˆâ–        | 3531/23840 [00:00<00:04, 4572.01 examples/s]Adding EOS to train dataset:  17%|â–ˆâ–‹        | 4000/23840 [00:00<00:04, 4122.03 examples/s]Adding EOS to train dataset:  19%|â–ˆâ–‰        | 4533/23840 [00:01<00:04, 4439.59 examples/s]Adding EOS to train dataset:  21%|â–ˆâ–ˆ        | 5000/23840 [00:01<00:04, 4274.62 examples/s]Adding EOS to train dataset:  23%|â–ˆâ–ˆâ–Ž       | 5532/23840 [00:01<00:04, 4556.10 examples/s]Adding EOS to train dataset:  25%|â–ˆâ–ˆâ–Œ       | 6000/23840 [00:01<00:04, 4347.16 examples/s]Adding EOS to train dataset:  27%|â–ˆâ–ˆâ–‹       | 6528/23840 [00:01<00:03, 4600.35 examples/s]Adding EOS to train dataset:  29%|â–ˆâ–ˆâ–‰       | 7000/23840 [00:01<00:03, 4351.87 examples/s]Adding EOS to train dataset:  32%|â–ˆâ–ˆâ–ˆâ–      | 7526/23840 [00:01<00:03, 4599.00 examples/s]Adding EOS to train dataset:  34%|â–ˆâ–ˆâ–ˆâ–Ž      | 8000/23840 [00:01<00:04, 3935.00 examples/s]Adding EOS to train dataset:  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 8529/23840 [00:01<00:03, 4276.46 examples/s]Adding EOS to train dataset:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 9000/23840 [00:02<00:03, 4165.86 examples/s]Adding EOS to train dataset:  40%|â–ˆâ–ˆâ–ˆâ–‰      | 9529/23840 [00:02<00:03, 4461.95 examples/s]Adding EOS to train dataset:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 10000/23840 [00:02<00:03, 4286.02 examples/s]Adding EOS to train dataset:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 10531/23840 [00:02<00:02, 4561.15 examples/s]Adding EOS to train dataset:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 11000/23840 [00:02<00:02, 4350.08 examples/s]Adding EOS to train dataset:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 11529/23840 [00:02<00:02, 4605.27 examples/s]Adding EOS to train dataset:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 12000/23840 [00:02<00:02, 4384.34 examples/s]Adding EOS to train dataset:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 12528/23840 [00:02<00:02, 4627.82 examples/s]Adding EOS to train dataset:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 13000/23840 [00:02<00:02, 4398.17 examples/s]Adding EOS to train dataset:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 13523/23840 [00:03<00:02, 4623.57 examples/s]Adding EOS to train dataset:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 14000/23840 [00:03<00:02, 4369.54 examples/s]Adding EOS to train dataset:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 14533/23840 [00:03<00:02, 4628.61 examples/s]Adding EOS to train dataset:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 15267/23840 [00:03<00:02, 3773.41 examples/s]Adding EOS to train dataset:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 15801/23840 [00:03<00:01, 4116.18 examples/s]Adding EOS to train dataset:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 16268/23840 [00:03<00:01, 4063.33 examples/s]Adding EOS to train dataset:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 16799/23840 [00:03<00:01, 4367.69 examples/s]Adding EOS to train dataset:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 17267/23840 [00:03<00:01, 4235.40 examples/s]Adding EOS to train dataset:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 17799/23840 [00:04<00:01, 4518.11 examples/s]Adding EOS to train dataset:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 18532/23840 [00:04<00:01, 4430.89 examples/s]Adding EOS to train dataset:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 19000/23840 [00:04<00:01, 4289.86 examples/s]Adding EOS to train dataset:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 19531/23840 [00:04<00:00, 4544.28 examples/s]Adding EOS to train dataset:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 20000/23840 [00:04<00:00, 4359.44 examples/s]Adding EOS to train dataset:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 20527/23840 [00:04<00:00, 4597.52 examples/s]Adding EOS to train dataset:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 21000/23840 [00:04<00:00, 4388.30 examples/s]Adding EOS to train dataset:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 21527/23840 [00:04<00:00, 4623.86 examples/s]Adding EOS to train dataset:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 22000/23840 [00:05<00:00, 4388.02 examples/s]Adding EOS to train dataset:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 22535/23840 [00:05<00:00, 4648.86 examples/s]Adding EOS to train dataset:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 23264/23840 [00:05<00:00, 4519.05 examples/s]Adding EOS to train dataset: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 23794/23840 [00:05<00:00, 4713.75 examples/s]Adding EOS to train dataset: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 23840/23840 [00:05<00:00, 4395.50 examples/s]
Tokenizing train dataset:   0%|          | 0/23840 [00:00<?, ? examples/s]Tokenizing train dataset:   0%|          | 44/23840 [00:00<00:55, 426.01 examples/s]Tokenizing train dataset:   0%|          | 95/23840 [00:00<00:50, 468.19 examples/s]Tokenizing train dataset:   1%|          | 142/23840 [00:00<00:50, 467.62 examples/s]Tokenizing train dataset:   1%|          | 194/23840 [00:00<00:48, 483.21 examples/s]Tokenizing train dataset:   1%|          | 245/23840 [00:00<00:47, 492.03 examples/s]Tokenizing train dataset:   1%|          | 295/23840 [00:00<00:47, 490.78 examples/s]Tokenizing train dataset:   2%|â–         | 368/23840 [00:00<00:48, 484.39 examples/s]Tokenizing train dataset:   2%|â–         | 420/23840 [00:00<00:47, 488.11 examples/s]Tokenizing train dataset:   2%|â–         | 469/23840 [00:00<00:47, 487.09 examples/s]Tokenizing train dataset:   2%|â–         | 521/23840 [00:01<00:47, 495.33 examples/s]Tokenizing train dataset:   2%|â–         | 574/23840 [00:01<00:46, 500.34 examples/s]Tokenizing train dataset:   3%|â–Ž         | 626/23840 [00:01<00:46, 501.64 examples/s]Tokenizing train dataset:   3%|â–Ž         | 678/23840 [00:01<00:45, 505.13 examples/s]Tokenizing train dataset:   3%|â–Ž         | 733/23840 [00:01<00:44, 516.74 examples/s]Tokenizing train dataset:   3%|â–Ž         | 807/23840 [00:01<00:45, 505.25 examples/s]Tokenizing train dataset:   4%|â–Ž         | 861/23840 [00:01<00:44, 510.69 examples/s]Tokenizing train dataset:   4%|â–         | 937/23840 [00:01<00:45, 507.02 examples/s]Tokenizing train dataset:   4%|â–         | 1000/23840 [00:02<01:05, 346.95 examples/s]Tokenizing train dataset:   4%|â–         | 1046/23840 [00:02<01:02, 367.46 examples/s]Tokenizing train dataset:   5%|â–         | 1094/23840 [00:02<00:58, 388.82 examples/s]Tokenizing train dataset:   5%|â–         | 1142/23840 [00:02<00:55, 407.08 examples/s]Tokenizing train dataset:   5%|â–         | 1191/23840 [00:02<00:53, 425.99 examples/s]Tokenizing train dataset:   5%|â–Œ         | 1240/23840 [00:02<00:51, 439.25 examples/s]Tokenizing train dataset:   5%|â–Œ         | 1289/23840 [00:02<00:49, 452.44 examples/s]Tokenizing train dataset:   6%|â–Œ         | 1341/23840 [00:02<00:48, 467.19 examples/s]Tokenizing train dataset:   6%|â–Œ         | 1412/23840 [00:03<00:48, 463.44 examples/s]Tokenizing train dataset:   6%|â–Œ         | 1463/23840 [00:03<00:47, 472.66 examples/s]Tokenizing train dataset:   6%|â–‹         | 1536/23840 [00:03<00:46, 475.40 examples/s]Tokenizing train dataset:   7%|â–‹         | 1585/23840 [00:03<00:46, 477.18 examples/s]Tokenizing train dataset:   7%|â–‹         | 1638/23840 [00:03<00:45, 489.49 examples/s]Tokenizing train dataset:   7%|â–‹         | 1689/23840 [00:03<00:45, 491.76 examples/s]Tokenizing train dataset:   7%|â–‹         | 1742/23840 [00:03<00:44, 500.32 examples/s]Tokenizing train dataset:   8%|â–Š         | 1794/23840 [00:03<00:44, 499.90 examples/s]Tokenizing train dataset:   8%|â–Š         | 1845/23840 [00:03<00:43, 500.91 examples/s]Tokenizing train dataset:   8%|â–Š         | 1920/23840 [00:04<00:44, 493.24 examples/s]Tokenizing train dataset:   8%|â–Š         | 1970/23840 [00:04<00:44, 492.63 examples/s]Tokenizing train dataset:   8%|â–Š         | 2021/23840 [00:04<01:09, 315.55 examples/s]Tokenizing train dataset:   9%|â–Š         | 2070/23840 [00:04<01:02, 348.20 examples/s]Tokenizing train dataset:   9%|â–‰         | 2120/23840 [00:04<00:57, 379.95 examples/s]Tokenizing train dataset:   9%|â–‰         | 2171/23840 [00:04<00:53, 408.63 examples/s]Tokenizing train dataset:   9%|â–‰         | 2218/23840 [00:04<00:51, 421.51 examples/s]Tokenizing train dataset:  10%|â–‰         | 2265/23840 [00:05<00:49, 432.34 examples/s]Tokenizing train dataset:  10%|â–‰         | 2314/23840 [00:05<00:48, 444.85 examples/s]Tokenizing train dataset:  10%|â–‰         | 2361/23840 [00:05<00:47, 449.78 examples/s]Tokenizing train dataset:  10%|â–ˆ         | 2408/23840 [00:05<00:47, 453.56 examples/s]Tokenizing train dataset:  10%|â–ˆ         | 2458/23840 [00:05<00:45, 465.07 examples/s]Tokenizing train dataset:  11%|â–ˆ         | 2531/23840 [00:05<00:45, 469.10 examples/s]Tokenizing train dataset:  11%|â–ˆ         | 2604/23840 [00:05<00:44, 473.66 examples/s]Tokenizing train dataset:  11%|â–ˆ         | 2655/23840 [00:05<00:44, 480.53 examples/s]Tokenizing train dataset:  11%|â–ˆâ–        | 2704/23840 [00:05<00:44, 478.99 examples/s]Tokenizing train dataset:  12%|â–ˆâ–        | 2755/23840 [00:06<00:43, 486.55 examples/s]Tokenizing train dataset:  12%|â–ˆâ–        | 2805/23840 [00:06<00:42, 489.97 examples/s]Tokenizing train dataset:  12%|â–ˆâ–        | 2856/23840 [00:06<00:42, 492.77 examples/s]Tokenizing train dataset:  12%|â–ˆâ–        | 2929/23840 [00:06<00:42, 488.23 examples/s]Tokenizing train dataset:  13%|â–ˆâ–Ž        | 2984/23840 [00:06<00:41, 501.76 examples/s]Tokenizing train dataset:  13%|â–ˆâ–Ž        | 3044/23840 [00:07<01:29, 232.08 examples/s]Tokenizing train dataset:  13%|â–ˆâ–Ž        | 3093/23840 [00:07<01:17, 269.33 examples/s]Tokenizing train dataset:  13%|â–ˆâ–Ž        | 3143/23840 [00:07<01:07, 307.91 examples/s]Tokenizing train dataset:  13%|â–ˆâ–Ž        | 3191/23840 [00:07<01:00, 340.29 examples/s]Tokenizing train dataset:  14%|â–ˆâ–Ž        | 3241/23840 [00:07<00:55, 374.10 examples/s]Tokenizing train dataset:  14%|â–ˆâ–        | 3293/23840 [00:07<00:50, 405.42 examples/s]Tokenizing train dataset:  14%|â–ˆâ–        | 3366/23840 [00:07<00:47, 430.26 examples/s]Tokenizing train dataset:  14%|â–ˆâ–        | 3414/23840 [00:07<00:46, 439.68 examples/s]Tokenizing train dataset:  15%|â–ˆâ–        | 3462/23840 [00:07<00:45, 446.02 examples/s]Tokenizing train dataset:  15%|â–ˆâ–        | 3512/23840 [00:08<00:44, 456.10 examples/s]Tokenizing train dataset:  15%|â–ˆâ–        | 3561/23840 [00:08<00:43, 461.07 examples/s]Tokenizing train dataset:  15%|â–ˆâ–Œ        | 3629/23840 [00:08<00:44, 455.11 examples/s]Tokenizing train dataset:  15%|â–ˆâ–Œ        | 3679/23840 [00:08<00:43, 463.88 examples/s]Tokenizing train dataset:  16%|â–ˆâ–Œ        | 3751/23840 [00:08<00:43, 466.15 examples/s]Tokenizing train dataset:  16%|â–ˆâ–Œ        | 3800/23840 [00:08<00:42, 471.61 examples/s]Tokenizing train dataset:  16%|â–ˆâ–Œ        | 3851/23840 [00:08<00:41, 476.52 examples/s]Tokenizing train dataset:  16%|â–ˆâ–‹        | 3902/23840 [00:08<00:41, 484.03 examples/s]Tokenizing train dataset:  17%|â–ˆâ–‹        | 3954/23840 [00:08<00:40, 492.43 examples/s]Tokenizing train dataset:  17%|â–ˆâ–‹        | 4024/23840 [00:09<00:59, 330.57 examples/s]Tokenizing train dataset:  17%|â–ˆâ–‹        | 4071/23840 [00:09<00:55, 356.29 examples/s]Tokenizing train dataset:  17%|â–ˆâ–‹        | 4122/23840 [00:09<00:50, 388.58 examples/s]Tokenizing train dataset:  18%|â–ˆâ–Š        | 4175/23840 [00:09<00:46, 420.75 examples/s]Tokenizing train dataset:  18%|â–ˆâ–Š        | 4223/23840 [00:09<00:45, 433.66 examples/s]Tokenizing train dataset:  18%|â–ˆâ–Š        | 4272/23840 [00:09<00:43, 446.36 examples/s]Tokenizing train dataset:  18%|â–ˆâ–Š        | 4322/23840 [00:09<00:42, 459.08 examples/s]Tokenizing train dataset:  18%|â–ˆâ–Š        | 4370/23840 [00:10<00:42, 462.53 examples/s]Tokenizing train dataset:  19%|â–ˆâ–Š        | 4418/23840 [00:10<00:41, 465.78 examples/s]Tokenizing train dataset:  19%|â–ˆâ–Š        | 4466/23840 [00:10<00:41, 463.91 examples/s]Tokenizing train dataset:  19%|â–ˆâ–‰        | 4517/23840 [00:10<00:40, 474.32 examples/s]Tokenizing train dataset:  19%|â–ˆâ–‰        | 4566/23840 [00:10<00:40, 476.60 examples/s]Tokenizing train dataset:  19%|â–ˆâ–‰        | 4616/23840 [00:10<00:40, 479.88 examples/s]Tokenizing train dataset:  20%|â–ˆâ–‰        | 4689/23840 [00:10<00:39, 480.41 examples/s]Tokenizing train dataset:  20%|â–ˆâ–‰        | 4739/23840 [00:10<00:39, 483.01 examples/s]Tokenizing train dataset:  20%|â–ˆâ–ˆ        | 4788/23840 [00:10<00:39, 483.39 examples/s]Tokenizing train dataset:  20%|â–ˆâ–ˆ        | 4842/23840 [00:10<00:38, 498.75 examples/s]Tokenizing train dataset:  21%|â–ˆâ–ˆ        | 4897/23840 [00:11<00:37, 511.78 examples/s]Tokenizing train dataset:  21%|â–ˆâ–ˆ        | 4972/23840 [00:11<00:37, 503.28 examples/s]Tokenizing train dataset:  21%|â–ˆâ–ˆ        | 5041/23840 [00:11<00:59, 313.74 examples/s]Tokenizing train dataset:  21%|â–ˆâ–ˆâ–       | 5090/23840 [00:11<00:54, 343.58 examples/s]Tokenizing train dataset:  22%|â–ˆâ–ˆâ–       | 5141/23840 [00:11<00:49, 375.54 examples/s]Tokenizing train dataset:  22%|â–ˆâ–ˆâ–       | 5190/23840 [00:11<00:46, 399.25 examples/s]Tokenizing train dataset:  22%|â–ˆâ–ˆâ–       | 5240/23840 [00:12<00:44, 422.57 examples/s]Tokenizing train dataset:  22%|â–ˆâ–ˆâ–       | 5290/23840 [00:12<00:42, 440.34 examples/s]Tokenizing train dataset:  22%|â–ˆâ–ˆâ–       | 5339/23840 [00:12<00:41, 450.90 examples/s]Tokenizing train dataset:  23%|â–ˆâ–ˆâ–Ž       | 5387/23840 [00:12<00:40, 457.10 examples/s]Tokenizing train dataset:  23%|â–ˆâ–ˆâ–Ž       | 5436/23840 [00:12<00:39, 462.84 examples/s]Tokenizing train dataset:  23%|â–ˆâ–ˆâ–Ž       | 5485/23840 [00:12<00:39, 467.39 examples/s]Tokenizing train dataset:  23%|â–ˆâ–ˆâ–Ž       | 5556/23840 [00:12<00:39, 468.18 examples/s]Tokenizing train dataset:  24%|â–ˆâ–ˆâ–Ž       | 5605/23840 [00:12<00:38, 468.42 examples/s]Tokenizing train dataset:  24%|â–ˆâ–ˆâ–       | 5677/23840 [00:12<00:38, 469.89 examples/s]Tokenizing train dataset:  24%|â–ˆâ–ˆâ–       | 5725/23840 [00:13<00:38, 471.19 examples/s]Tokenizing train dataset:  24%|â–ˆâ–ˆâ–       | 5775/23840 [00:13<00:37, 475.82 examples/s]Tokenizing train dataset:  24%|â–ˆâ–ˆâ–       | 5825/23840 [00:13<00:37, 479.26 examples/s]Tokenizing train dataset:  25%|â–ˆâ–ˆâ–       | 5877/23840 [00:13<00:36, 488.45 examples/s]Tokenizing train dataset:  25%|â–ˆâ–ˆâ–       | 5952/23840 [00:13<00:36, 489.02 examples/s]Tokenizing train dataset:  25%|â–ˆâ–ˆâ–Œ       | 6023/23840 [00:13<00:52, 340.40 examples/s]Tokenizing train dataset:  25%|â–ˆâ–ˆâ–Œ       | 6071/23840 [00:13<00:48, 365.41 examples/s]Tokenizing train dataset:  26%|â–ˆâ–ˆâ–Œ       | 6120/23840 [00:14<00:45, 390.50 examples/s]Tokenizing train dataset:  26%|â–ˆâ–ˆâ–Œ       | 6169/23840 [00:14<00:42, 411.97 examples/s]Tokenizing train dataset:  26%|â–ˆâ–ˆâ–Œ       | 6217/23840 [00:14<00:41, 427.69 examples/s]Tokenizing train dataset:  26%|â–ˆâ–ˆâ–‹       | 6268/23840 [00:14<00:39, 445.51 examples/s]Tokenizing train dataset:  26%|â–ˆâ–ˆâ–‹       | 6317/23840 [00:14<00:38, 454.49 examples/s]Tokenizing train dataset:  27%|â–ˆâ–ˆâ–‹       | 6387/23840 [00:14<00:38, 456.79 examples/s]Tokenizing train dataset:  27%|â–ˆâ–ˆâ–‹       | 6437/23840 [00:14<00:37, 467.48 examples/s]Tokenizing train dataset:  27%|â–ˆâ–ˆâ–‹       | 6488/23840 [00:14<00:36, 478.15 examples/s]Tokenizing train dataset:  27%|â–ˆâ–ˆâ–‹       | 6538/23840 [00:14<00:36, 478.47 examples/s]Tokenizing train dataset:  28%|â–ˆâ–ˆâ–Š       | 6589/23840 [00:15<00:35, 485.98 examples/s]Tokenizing train dataset:  28%|â–ˆâ–ˆâ–Š       | 6640/23840 [00:15<00:35, 488.83 examples/s]Tokenizing train dataset:  28%|â–ˆâ–ˆâ–Š       | 6712/23840 [00:15<00:35, 482.61 examples/s]Tokenizing train dataset:  28%|â–ˆâ–ˆâ–Š       | 6764/23840 [00:15<00:35, 483.96 examples/s]Tokenizing train dataset:  29%|â–ˆâ–ˆâ–Š       | 6813/23840 [00:15<00:35, 485.08 examples/s]Tokenizing train dataset:  29%|â–ˆâ–ˆâ–‰       | 6862/23840 [00:15<00:35, 483.27 examples/s]Tokenizing train dataset:  29%|â–ˆâ–ˆâ–‰       | 6915/23840 [00:15<00:34, 493.42 examples/s]Tokenizing train dataset:  29%|â–ˆâ–ˆâ–‰       | 6967/23840 [00:15<00:33, 497.35 examples/s]Tokenizing train dataset:  29%|â–ˆâ–ˆâ–‰       | 7021/23840 [00:16<00:52, 319.75 examples/s]Tokenizing train dataset:  30%|â–ˆâ–ˆâ–‰       | 7069/23840 [00:16<00:47, 351.69 examples/s]Tokenizing train dataset:  30%|â–ˆâ–ˆâ–‰       | 7120/23840 [00:16<00:43, 385.04 examples/s]Tokenizing train dataset:  30%|â–ˆâ–ˆâ–ˆ       | 7172/23840 [00:16<00:40, 414.58 examples/s]Tokenizing train dataset:  30%|â–ˆâ–ˆâ–ˆ       | 7221/23840 [00:16<00:38, 431.71 examples/s]Tokenizing train dataset:  31%|â–ˆâ–ˆâ–ˆ       | 7276/23840 [00:16<00:35, 460.70 examples/s]Tokenizing train dataset:  31%|â–ˆâ–ˆâ–ˆ       | 7346/23840 [00:16<00:36, 457.08 examples/s]Tokenizing train dataset:  31%|â–ˆâ–ˆâ–ˆ       | 7396/23840 [00:16<00:35, 464.71 examples/s]Tokenizing train dataset:  31%|â–ˆâ–ˆâ–ˆ       | 7446/23840 [00:16<00:34, 470.74 examples/s]Tokenizing train dataset:  31%|â–ˆâ–ˆâ–ˆâ–      | 7496/23840 [00:17<00:34, 475.04 examples/s]Tokenizing train dataset:  32%|â–ˆâ–ˆâ–ˆâ–      | 7567/23840 [00:17<00:34, 471.40 examples/s]Tokenizing train dataset:  32%|â–ˆâ–ˆâ–ˆâ–      | 7640/23840 [00:17<00:34, 474.97 examples/s]Tokenizing train dataset:  32%|â–ˆâ–ˆâ–ˆâ–      | 7693/23840 [00:17<00:33, 484.31 examples/s]Tokenizing train dataset:  32%|â–ˆâ–ˆâ–ˆâ–      | 7746/23840 [00:17<00:32, 494.56 examples/s]Tokenizing train dataset:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 7798/23840 [00:17<00:32, 496.34 examples/s]Tokenizing train dataset:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 7848/23840 [00:17<00:32, 490.55 examples/s]Tokenizing train dataset:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 7921/23840 [00:17<00:32, 486.94 examples/s]Tokenizing train dataset:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 7973/23840 [00:18<00:32, 490.86 examples/s]Tokenizing train dataset:  34%|â–ˆâ–ˆâ–ˆâ–Ž      | 8045/23840 [00:18<00:47, 335.84 examples/s]Tokenizing train dataset:  34%|â–ˆâ–ˆâ–ˆâ–      | 8094/23840 [00:18<00:43, 364.02 examples/s]Tokenizing train dataset:  34%|â–ˆâ–ˆâ–ˆâ–      | 8146/23840 [00:18<00:39, 395.22 examples/s]Tokenizing train dataset:  34%|â–ˆâ–ˆâ–ˆâ–      | 8195/23840 [00:18<00:37, 416.31 examples/s]Tokenizing train dataset:  35%|â–ˆâ–ˆâ–ˆâ–      | 8248/23840 [00:18<00:35, 441.68 examples/s]Tokenizing train dataset:  35%|â–ˆâ–ˆâ–ˆâ–      | 8297/23840 [00:18<00:34, 450.62 examples/s]Tokenizing train dataset:  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 8349/23840 [00:18<00:33, 464.37 examples/s]Tokenizing train dataset:  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 8423/23840 [00:19<00:32, 473.68 examples/s]Tokenizing train dataset:  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 8496/23840 [00:19<00:32, 474.48 examples/s]Tokenizing train dataset:  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 8545/23840 [00:19<00:32, 476.14 examples/s]Tokenizing train dataset:  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 8594/23840 [00:19<00:31, 476.94 examples/s]Tokenizing train dataset:  36%|â–ˆâ–ˆâ–ˆâ–‹      | 8647/23840 [00:19<00:31, 488.58 examples/s]Tokenizing train dataset:  36%|â–ˆâ–ˆâ–ˆâ–‹      | 8697/23840 [00:19<00:49, 307.30 examples/s]Tokenizing train dataset:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 8750/23840 [00:20<00:43, 349.77 examples/s]Tokenizing train dataset:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 8798/23840 [00:20<00:39, 377.45 examples/s]Tokenizing train dataset:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 8848/23840 [00:20<00:37, 403.46 examples/s]Tokenizing train dataset:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 8898/23840 [00:20<00:35, 426.17 examples/s]Tokenizing train dataset:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 8950/23840 [00:20<00:33, 447.53 examples/s]Tokenizing train dataset:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 8998/23840 [00:20<00:32, 455.05 examples/s]Tokenizing train dataset:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 9046/23840 [00:20<00:48, 302.33 examples/s]Tokenizing train dataset:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 9095/23840 [00:20<00:43, 339.67 examples/s]Tokenizing train dataset:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 9144/23840 [00:21<00:39, 371.24 examples/s]Tokenizing train dataset:  39%|â–ˆâ–ˆâ–ˆâ–Š      | 9192/23840 [00:21<00:36, 396.83 examples/s]Tokenizing train dataset:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 9242/23840 [00:21<00:34, 420.13 examples/s]Tokenizing train dataset:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 9292/23840 [00:21<00:33, 436.73 examples/s]Tokenizing train dataset:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 9340/23840 [00:21<00:32, 446.61 examples/s]Tokenizing train dataset:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 9388/23840 [00:21<00:31, 454.07 examples/s]Tokenizing train dataset:  40%|â–ˆâ–ˆâ–ˆâ–‰      | 9441/23840 [00:21<00:30, 472.88 examples/s]Tokenizing train dataset:  40%|â–ˆâ–ˆâ–ˆâ–‰      | 9514/23840 [00:21<00:30, 472.81 examples/s]Tokenizing train dataset:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 9563/23840 [00:21<00:30, 473.97 examples/s]Tokenizing train dataset:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 9611/23840 [00:21<00:30, 473.29 examples/s]Tokenizing train dataset:  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 9659/23840 [00:22<00:30, 471.56 examples/s]Tokenizing train dataset:  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 9708/23840 [00:22<00:29, 474.85 examples/s]Tokenizing train dataset:  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 9756/23840 [00:22<00:29, 473.40 examples/s]Tokenizing train dataset:  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 9806/23840 [00:22<00:29, 475.98 examples/s]Tokenizing train dataset:  41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 9858/23840 [00:22<00:28, 487.37 examples/s]Tokenizing train dataset:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 9911/23840 [00:22<00:28, 495.42 examples/s]Tokenizing train dataset:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 9962/23840 [00:22<00:28, 494.02 examples/s]Tokenizing train dataset:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 10020/23840 [00:23<00:49, 279.50 examples/s]Tokenizing train dataset:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 10069/23840 [00:23<00:43, 317.27 examples/s]Tokenizing train dataset:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 10115/23840 [00:23<00:39, 345.70 examples/s]Tokenizing train dataset:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 10166/23840 [00:23<00:35, 381.14 examples/s]Tokenizing train dataset:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 10216/23840 [00:23<00:33, 407.54 examples/s]Tokenizing train dataset:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 10265/23840 [00:23<00:32, 423.22 examples/s]Tokenizing train dataset:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 10314/23840 [00:23<00:30, 438.53 examples/s]Tokenizing train dataset:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 10364/23840 [00:23<00:29, 452.96 examples/s]Tokenizing train dataset:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 10432/23840 [00:23<00:29, 447.72 examples/s]Tokenizing train dataset:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 10480/23840 [00:24<00:29, 453.18 examples/s]Tokenizing train dataset:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 10529/23840 [00:24<00:28, 460.40 examples/s]Tokenizing train dataset:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 10581/23840 [00:24<00:27, 476.43 examples/s]Tokenizing train dataset:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 10631/23840 [00:24<00:27, 478.54 examples/s]Tokenizing train dataset:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 10681/23840 [00:24<00:27, 483.68 examples/s]Tokenizing train dataset:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 10733/23840 [00:24<00:26, 492.49 examples/s]Tokenizing train dataset:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 10784/23840 [00:24<00:26, 495.22 examples/s]Tokenizing train dataset:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 10855/23840 [00:24<00:26, 484.19 examples/s]Tokenizing train dataset:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 10905/23840 [00:24<00:26, 486.90 examples/s]Tokenizing train dataset:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 10958/23840 [00:25<00:25, 496.10 examples/s]Tokenizing train dataset:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 11021/23840 [00:25<00:38, 328.89 examples/s]Tokenizing train dataset:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 11070/23840 [00:25<00:35, 359.76 examples/s]Tokenizing train dataset:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 11119/23840 [00:25<00:32, 387.28 examples/s]Tokenizing train dataset:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 11168/23840 [00:25<00:30, 410.31 examples/s]Tokenizing train dataset:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 11236/23840 [00:25<00:29, 421.92 examples/s]Tokenizing train dataset:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 11286/23840 [00:25<00:28, 438.23 examples/s]Tokenizing train dataset:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 11336/23840 [00:26<00:27, 451.80 examples/s]Tokenizing train dataset:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 11387/23840 [00:26<00:26, 464.91 examples/s]Tokenizing train dataset:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 11437/23840 [00:26<00:26, 472.49 examples/s]Tokenizing train dataset:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 11510/23840 [00:26<00:26, 470.86 examples/s]Tokenizing train dataset:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 11558/23840 [00:26<00:26, 471.32 examples/s]Tokenizing train dataset:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 11625/23840 [00:26<00:26, 459.43 examples/s]Tokenizing train dataset:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 11676/23840 [00:26<00:25, 470.01 examples/s]Tokenizing train dataset:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 11724/23840 [00:26<00:25, 469.38 examples/s]Tokenizing train dataset:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 11794/23840 [00:26<00:25, 464.26 examples/s]Tokenizing train dataset:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 11846/23840 [00:27<00:25, 475.39 examples/s]Tokenizing train dataset:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 11898/23840 [00:27<00:24, 483.74 examples/s]Tokenizing train dataset:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 11953/23840 [00:27<00:23, 496.80 examples/s]Tokenizing train dataset:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 12023/23840 [00:27<00:35, 332.37 examples/s]Tokenizing train dataset:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 12071/23840 [00:27<00:32, 359.22 examples/s]Tokenizing train dataset:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 12119/23840 [00:27<00:30, 383.94 examples/s]Tokenizing train dataset:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 12166/23840 [00:27<00:29, 400.50 examples/s]Tokenizing train dataset:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 12216/23840 [00:28<00:27, 423.23 examples/s]Tokenizing train dataset:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 12283/23840 [00:28<00:26, 430.07 examples/s]Tokenizing train dataset:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 12331/23840 [00:28<00:26, 439.14 examples/s]Tokenizing train dataset:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 12378/23840 [00:28<00:25, 445.40 examples/s]Tokenizing train dataset:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 12427/23840 [00:28<00:25, 455.06 examples/s]Tokenizing train dataset:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 12477/23840 [00:28<00:24, 465.76 examples/s]Tokenizing train dataset:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 12526/23840 [00:28<00:24, 462.53 examples/s]Tokenizing train dataset:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 12577/23840 [00:28<00:23, 471.86 examples/s]Tokenizing train dataset:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 12625/23840 [00:28<00:23, 471.82 examples/s]Tokenizing train dataset:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 12697/23840 [00:29<00:23, 469.89 examples/s]Tokenizing train dataset:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 12747/23840 [00:29<00:23, 476.92 examples/s]Tokenizing train dataset:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 12800/23840 [00:29<00:22, 485.79 examples/s]Tokenizing train dataset:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 12851/23840 [00:29<00:22, 488.07 examples/s]Tokenizing train dataset:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 12900/23840 [00:29<00:22, 487.76 examples/s]Tokenizing train dataset:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 12950/23840 [00:29<00:22, 487.84 examples/s]Tokenizing train dataset:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 12999/23840 [00:29<00:22, 487.35 examples/s]Tokenizing train dataset:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 13068/23840 [00:30<00:33, 321.70 examples/s]Tokenizing train dataset:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 13118/23840 [00:30<00:30, 355.04 examples/s]Tokenizing train dataset:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 13166/23840 [00:30<00:27, 381.30 examples/s]Tokenizing train dataset:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 13216/23840 [00:30<00:26, 408.33 examples/s]Tokenizing train dataset:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 13265/23840 [00:30<00:24, 426.29 examples/s]Tokenizing train dataset:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 13316/23840 [00:30<00:23, 444.24 examples/s]Tokenizing train dataset:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 13368/23840 [00:30<00:22, 463.39 examples/s]Tokenizing train dataset:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 13417/23840 [00:30<00:22, 468.31 examples/s]Tokenizing train dataset:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 13466/23840 [00:30<00:22, 469.82 examples/s]Tokenizing train dataset:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 13516/23840 [00:30<00:21, 476.90 examples/s]Tokenizing train dataset:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 13568/23840 [00:31<00:21, 486.71 examples/s]Tokenizing train dataset:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 13637/23840 [00:31<00:21, 475.49 examples/s]Tokenizing train dataset:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 13687/23840 [00:31<00:21, 478.12 examples/s]Tokenizing train dataset:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 13736/23840 [00:31<00:21, 479.74 examples/s]Tokenizing train dataset:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 13806/23840 [00:31<00:21, 473.79 examples/s]Tokenizing train dataset:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 13876/23840 [00:31<00:21, 469.03 examples/s]Tokenizing train dataset:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 13925/23840 [00:31<00:21, 471.21 examples/s]Tokenizing train dataset:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 13977/23840 [00:31<00:20, 481.00 examples/s]Tokenizing train dataset:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 14047/23840 [00:32<00:29, 332.47 examples/s]Tokenizing train dataset:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 14095/23840 [00:32<00:27, 359.22 examples/s]Tokenizing train dataset:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 14145/23840 [00:32<00:25, 385.47 examples/s]Tokenizing train dataset:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 14196/23840 [00:32<00:23, 412.99 examples/s]Tokenizing train dataset:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 14243/23840 [00:32<00:22, 424.99 examples/s]Tokenizing train dataset:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 14289/23840 [00:32<00:33, 282.61 examples/s]Tokenizing train dataset:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 14338/23840 [00:33<00:29, 322.08 examples/s]Tokenizing train dataset:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 14389/23840 [00:33<00:26, 360.86 examples/s]Tokenizing train dataset:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 14440/23840 [00:33<00:23, 394.28 examples/s]Tokenizing train dataset:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 14495/23840 [00:33<00:21, 432.90 examples/s]Tokenizing train dataset:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 14567/23840 [00:33<00:20, 447.50 examples/s]Tokenizing train dataset:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 14618/23840 [00:33<00:19, 462.02 examples/s]Tokenizing train dataset:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 14671/23840 [00:33<00:19, 477.23 examples/s]Tokenizing train dataset:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 14722/23840 [00:33<00:18, 483.88 examples/s]Tokenizing train dataset:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 14775/23840 [00:33<00:18, 494.94 examples/s]Tokenizing train dataset:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 14827/23840 [00:34<00:18, 499.23 examples/s]Tokenizing train dataset:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 14905/23840 [00:34<00:17, 502.60 examples/s]Tokenizing train dataset:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 14980/23840 [00:34<00:17, 499.85 examples/s]Tokenizing train dataset:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 15046/23840 [00:34<00:25, 343.95 examples/s]Tokenizing train dataset:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 15095/23840 [00:34<00:23, 369.88 examples/s]Tokenizing train dataset:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 15146/23840 [00:34<00:21, 395.38 examples/s]Tokenizing train dataset:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 15196/23840 [00:34<00:20, 416.63 examples/s]Tokenizing train dataset:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 15248/23840 [00:35<00:19, 440.43 examples/s]Tokenizing train dataset:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 15302/23840 [00:35<00:18, 463.21 examples/s]Tokenizing train dataset:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 15376/23840 [00:35<00:18, 468.89 examples/s]Tokenizing train dataset:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 15426/23840 [00:35<00:17, 474.33 examples/s]Tokenizing train dataset:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 15480/23840 [00:35<00:17, 488.69 examples/s]Tokenizing train dataset:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 15553/23840 [00:35<00:17, 485.22 examples/s]Tokenizing train dataset:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 15604/23840 [00:35<00:16, 488.24 examples/s]Tokenizing train dataset:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 15657/23840 [00:35<00:16, 496.22 examples/s]Tokenizing train dataset:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 15710/23840 [00:35<00:16, 503.02 examples/s]Tokenizing train dataset:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 15764/23840 [00:36<00:15, 508.39 examples/s]Tokenizing train dataset:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 15842/23840 [00:36<00:15, 507.74 examples/s]Tokenizing train dataset:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 15913/23840 [00:36<00:16, 494.51 examples/s]Tokenizing train dataset:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 15963/23840 [00:36<00:16, 491.78 examples/s]Tokenizing train dataset:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 16021/23840 [00:36<00:23, 335.71 examples/s]Tokenizing train dataset:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 16070/23840 [00:36<00:21, 365.24 examples/s]Tokenizing train dataset:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 16121/23840 [00:37<00:19, 395.06 examples/s]Tokenizing train dataset:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 16172/23840 [00:37<00:18, 417.83 examples/s]Tokenizing train dataset:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 16244/23840 [00:37<00:17, 433.38 examples/s]Tokenizing train dataset:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 16296/23840 [00:37<00:16, 451.12 examples/s]Tokenizing train dataset:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 16345/23840 [00:37<00:16, 458.79 examples/s]Tokenizing train dataset:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 16417/23840 [00:37<00:16, 462.14 examples/s]Tokenizing train dataset:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 16466/23840 [00:37<00:15, 466.19 examples/s]Tokenizing train dataset:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 16514/23840 [00:37<00:15, 467.18 examples/s]Tokenizing train dataset:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 16585/23840 [00:37<00:15, 467.87 examples/s]Tokenizing train dataset:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 16635/23840 [00:38<00:15, 472.37 examples/s]Tokenizing train dataset:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 16683/23840 [00:38<00:15, 473.10 examples/s]Tokenizing train dataset:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 16735/23840 [00:38<00:14, 483.38 examples/s]Tokenizing train dataset:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 16790/23840 [00:38<00:14, 500.04 examples/s]Tokenizing train dataset:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 16841/23840 [00:38<00:14, 497.56 examples/s]Tokenizing train dataset:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 16893/23840 [00:38<00:13, 503.28 examples/s]Tokenizing train dataset:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 16968/23840 [00:38<00:13, 497.11 examples/s]Tokenizing train dataset:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 17024/23840 [00:39<00:20, 338.17 examples/s]Tokenizing train dataset:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 17074/23840 [00:39<00:18, 368.20 examples/s]Tokenizing train dataset:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 17123/23840 [00:39<00:17, 393.24 examples/s]Tokenizing train dataset:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 17170/23840 [00:39<00:16, 408.33 examples/s]Tokenizing train dataset:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 17220/23840 [00:39<00:15, 430.15 examples/s]Tokenizing train dataset:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 17273/23840 [00:39<00:14, 453.16 examples/s]Tokenizing train dataset:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 17322/23840 [00:39<00:14, 461.37 examples/s]Tokenizing train dataset:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 17377/23840 [00:39<00:13, 482.09 examples/s]Tokenizing train dataset:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 17428/23840 [00:39<00:13, 487.77 examples/s]Tokenizing train dataset:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 17479/23840 [00:39<00:12, 492.66 examples/s]Tokenizing train dataset:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 17532/23840 [00:40<00:12, 498.35 examples/s]Tokenizing train dataset:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 17611/23840 [00:40<00:12, 505.72 examples/s]Tokenizing train dataset:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 17686/23840 [00:40<00:12, 501.65 examples/s]Tokenizing train dataset:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 17760/23840 [00:40<00:12, 496.41 examples/s]Tokenizing train dataset:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 17810/23840 [00:40<00:12, 496.32 examples/s]Tokenizing train dataset:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 17861/23840 [00:40<00:12, 493.98 examples/s]Tokenizing train dataset:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 17914/23840 [00:40<00:11, 501.13 examples/s]Tokenizing train dataset:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 17968/23840 [00:40<00:11, 509.40 examples/s]Tokenizing train dataset:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 18026/23840 [00:41<00:17, 341.83 examples/s]Tokenizing train dataset:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 18074/23840 [00:41<00:15, 367.86 examples/s]Tokenizing train dataset:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 18123/23840 [00:41<00:14, 392.90 examples/s]Tokenizing train dataset:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 18175/23840 [00:41<00:13, 420.56 examples/s]Tokenizing train dataset:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 18224/23840 [00:41<00:12, 437.74 examples/s]Tokenizing train dataset:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 18274/23840 [00:41<00:12, 452.49 examples/s]Tokenizing train dataset:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 18324/23840 [00:41<00:11, 461.77 examples/s]Tokenizing train dataset:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 18377/23840 [00:41<00:11, 477.69 examples/s]Tokenizing train dataset:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 18452/23840 [00:42<00:11, 483.36 examples/s]Tokenizing train dataset:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 18505/23840 [00:42<00:10, 494.56 examples/s]Tokenizing train dataset:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 18556/23840 [00:42<00:10, 495.53 examples/s]Tokenizing train dataset:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 18633/23840 [00:42<00:10, 496.38 examples/s]Tokenizing train dataset:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 18686/23840 [00:42<00:10, 502.72 examples/s]Tokenizing train dataset:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 18740/23840 [00:42<00:10, 507.26 examples/s]Tokenizing train dataset:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 18792/23840 [00:42<00:09, 506.31 examples/s]Tokenizing train dataset:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 18867/23840 [00:42<00:09, 500.76 examples/s]Tokenizing train dataset:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 18919/23840 [00:43<00:09, 500.90 examples/s]Tokenizing train dataset:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 18972/23840 [00:43<00:09, 505.16 examples/s]Tokenizing train dataset:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 19023/23840 [00:43<00:18, 255.28 examples/s]Tokenizing train dataset:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 19072/23840 [00:43<00:16, 292.07 examples/s]Tokenizing train dataset:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 19122/23840 [00:43<00:14, 328.97 examples/s]Tokenizing train dataset:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 19172/23840 [00:43<00:12, 364.03 examples/s]Tokenizing train dataset:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 19223/23840 [00:43<00:11, 395.03 examples/s]Tokenizing train dataset:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 19274/23840 [00:44<00:10, 422.60 examples/s]Tokenizing train dataset:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 19322/23840 [00:44<00:10, 435.65 examples/s]Tokenizing train dataset:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 19393/23840 [00:44<00:09, 446.67 examples/s]Tokenizing train dataset:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 19445/23840 [00:44<00:09, 464.05 examples/s]Tokenizing train dataset:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 19498/23840 [00:44<00:09, 479.29 examples/s]Tokenizing train dataset:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 19574/23840 [00:44<00:08, 484.97 examples/s]Tokenizing train dataset:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 19624/23840 [00:45<00:13, 315.94 examples/s]Tokenizing train dataset:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 19673/23840 [00:45<00:11, 347.40 examples/s]Tokenizing train dataset:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 19720/23840 [00:45<00:11, 371.88 examples/s]Tokenizing train dataset:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 19773/23840 [00:45<00:10, 406.52 examples/s]Tokenizing train dataset:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 19822/23840 [00:45<00:09, 424.72 examples/s]Tokenizing train dataset:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 19871/23840 [00:45<00:09, 438.33 examples/s]Tokenizing train dataset:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 19921/23840 [00:45<00:08, 452.48 examples/s]Tokenizing train dataset:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 19971/23840 [00:45<00:08, 464.54 examples/s]Tokenizing train dataset:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 20020/23840 [00:46<00:12, 303.97 examples/s]Tokenizing train dataset:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 20066/23840 [00:46<00:11, 334.18 examples/s]Tokenizing train dataset:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 20114/23840 [00:46<00:10, 365.48 examples/s]Tokenizing train dataset:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 20163/23840 [00:46<00:09, 393.33 examples/s]Tokenizing train dataset:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 20215/23840 [00:46<00:08, 424.65 examples/s]Tokenizing train dataset:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 20266/23840 [00:46<00:08, 444.63 examples/s]Tokenizing train dataset:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 20337/23840 [00:46<00:07, 451.77 examples/s]Tokenizing train dataset:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 20388/23840 [00:46<00:07, 465.26 examples/s]Tokenizing train dataset:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 20459/23840 [00:46<00:07, 464.25 examples/s]Tokenizing train dataset:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 20508/23840 [00:47<00:07, 469.94 examples/s]Tokenizing train dataset:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 20557/23840 [00:47<00:06, 473.46 examples/s]Tokenizing train dataset:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 20610/23840 [00:47<00:06, 484.26 examples/s]Tokenizing train dataset:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 20663/23840 [00:47<00:06, 495.98 examples/s]Tokenizing train dataset:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 20738/23840 [00:47<00:06, 493.52 examples/s]Tokenizing train dataset:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 20789/23840 [00:47<00:06, 496.05 examples/s]Tokenizing train dataset:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 20863/23840 [00:47<00:06, 491.94 examples/s]Tokenizing train dataset:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 20936/23840 [00:47<00:05, 486.13 examples/s]Tokenizing train dataset:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 20992/23840 [00:48<00:05, 501.44 examples/s]Tokenizing train dataset:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 21045/23840 [00:48<00:08, 332.51 examples/s]Tokenizing train dataset:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 21089/23840 [00:48<00:07, 351.61 examples/s]Tokenizing train dataset:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 21138/23840 [00:48<00:07, 379.79 examples/s]Tokenizing train dataset:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 21191/23840 [00:48<00:06, 412.40 examples/s]Tokenizing train dataset:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 21238/23840 [00:48<00:06, 426.43 examples/s]Tokenizing train dataset:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 21289/23840 [00:48<00:05, 443.62 examples/s]Tokenizing train dataset:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 21339/23840 [00:48<00:05, 456.60 examples/s]Tokenizing train dataset:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 21391/23840 [00:49<00:05, 469.19 examples/s]Tokenizing train dataset:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 21440/23840 [00:49<00:05, 473.64 examples/s]Tokenizing train dataset:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 21491/23840 [00:49<00:04, 479.87 examples/s]Tokenizing train dataset:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 21544/23840 [00:49<00:04, 492.45 examples/s]Tokenizing train dataset:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 21596/23840 [00:49<00:04, 498.89 examples/s]Tokenizing train dataset:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 21671/23840 [00:49<00:04, 494.76 examples/s]Tokenizing train dataset:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 21721/23840 [00:49<00:04, 491.67 examples/s]Tokenizing train dataset:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 21794/23840 [00:49<00:04, 485.88 examples/s]Tokenizing train dataset:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 21846/23840 [00:49<00:04, 492.67 examples/s]Tokenizing train dataset:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 21898/23840 [00:50<00:03, 497.75 examples/s]Tokenizing train dataset:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 21976/23840 [00:50<00:03, 503.48 examples/s]Tokenizing train dataset:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 22044/23840 [00:50<00:05, 345.04 examples/s]Tokenizing train dataset:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 22092/23840 [00:50<00:04, 368.45 examples/s]Tokenizing train dataset:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 22142/23840 [00:50<00:04, 394.10 examples/s]Tokenizing train dataset:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 22193/23840 [00:50<00:03, 417.94 examples/s]Tokenizing train dataset:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 22240/23840 [00:50<00:03, 426.96 examples/s]Tokenizing train dataset:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 22289/23840 [00:51<00:03, 439.85 examples/s]Tokenizing train dataset:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 22338/23840 [00:51<00:03, 451.26 examples/s]Tokenizing train dataset:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 22388/23840 [00:51<00:03, 461.16 examples/s]Tokenizing train dataset:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 22436/23840 [00:51<00:03, 463.96 examples/s]Tokenizing train dataset:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 22488/23840 [00:51<00:02, 474.20 examples/s]Tokenizing train dataset:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 22537/23840 [00:51<00:02, 474.05 examples/s]Tokenizing train dataset:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 22588/23840 [00:51<00:02, 479.81 examples/s]Tokenizing train dataset:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 22638/23840 [00:51<00:02, 483.06 examples/s]Tokenizing train dataset:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 22690/23840 [00:51<00:02, 491.31 examples/s]Tokenizing train dataset:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 22741/23840 [00:51<00:02, 495.17 examples/s]Tokenizing train dataset:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 22817/23840 [00:52<00:02, 494.15 examples/s]Tokenizing train dataset:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 22890/23840 [00:52<00:01, 485.66 examples/s]Tokenizing train dataset:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 22943/23840 [00:52<00:01, 495.46 examples/s]Tokenizing train dataset:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 22994/23840 [00:52<00:01, 495.72 examples/s]Tokenizing train dataset:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 23067/23840 [00:52<00:02, 334.92 examples/s]Tokenizing train dataset:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 23113/23840 [00:52<00:02, 355.70 examples/s]Tokenizing train dataset:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 23165/23840 [00:53<00:01, 387.83 examples/s]Tokenizing train dataset:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 23215/23840 [00:53<00:01, 411.01 examples/s]Tokenizing train dataset:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 23268/23840 [00:53<00:01, 437.66 examples/s]Tokenizing train dataset:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 23317/23840 [00:53<00:01, 449.31 examples/s]Tokenizing train dataset:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 23366/23840 [00:53<00:01, 455.07 examples/s]Tokenizing train dataset:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 23416/23840 [00:53<00:00, 466.93 examples/s]Tokenizing train dataset:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 23485/23840 [00:53<00:00, 461.31 examples/s]Tokenizing train dataset:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 23537/23840 [00:53<00:00, 473.55 examples/s]Tokenizing train dataset:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 23588/23840 [00:53<00:00, 480.72 examples/s]Tokenizing train dataset:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 23638/23840 [00:54<00:00, 483.41 examples/s]Tokenizing train dataset:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 23688/23840 [00:54<00:00, 484.97 examples/s]Tokenizing train dataset: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 23741/23840 [00:54<00:00, 496.99 examples/s]Tokenizing train dataset: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 23793/23840 [00:54<00:00, 499.63 examples/s]Tokenizing train dataset: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 23840/23840 [00:54<00:00, 436.79 examples/s]
Truncating train dataset:   0%|          | 0/23840 [00:00<?, ? examples/s]Truncating train dataset:  25%|â–ˆâ–ˆâ–Œ       | 6000/23840 [00:00<00:00, 52024.31 examples/s]Truncating train dataset:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 18000/23840 [00:00<00:00, 63645.82 examples/s]Truncating train dataset: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 23840/23840 [00:00<00:00, 48055.23 examples/s]
Applying formatting function to eval dataset:   0%|          | 0/5960 [00:00<?, ? examples/s]Applying formatting function to eval dataset:   6%|â–‹         | 378/5960 [00:00<00:01, 3720.96 examples/s]Applying formatting function to eval dataset:  13%|â–ˆâ–Ž        | 768/5960 [00:00<00:01, 3815.73 examples/s]Applying formatting function to eval dataset:  20%|â–ˆâ–‰        | 1188/5960 [00:00<00:01, 3018.55 examples/s]Applying formatting function to eval dataset:  28%|â–ˆâ–ˆâ–Š       | 1686/5960 [00:00<00:02, 2075.59 examples/s]Applying formatting function to eval dataset:  34%|â–ˆâ–ˆâ–ˆâ–Ž      | 2000/5960 [00:00<00:01, 2088.23 examples/s]Applying formatting function to eval dataset:  40%|â–ˆâ–ˆâ–ˆâ–‰      | 2381/5960 [00:00<00:01, 2456.60 examples/s]Applying formatting function to eval dataset:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2774/5960 [00:01<00:01, 2800.83 examples/s]Applying formatting function to eval dataset:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3190/5960 [00:01<00:01, 2677.42 examples/s]Applying formatting function to eval dataset:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3578/5960 [00:01<00:00, 2956.94 examples/s]Applying formatting function to eval dataset:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 3975/5960 [00:01<00:00, 3208.20 examples/s]Applying formatting function to eval dataset:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4385/5960 [00:01<00:00, 2780.49 examples/s]Applying formatting function to eval dataset:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4777/5960 [00:01<00:00, 3043.79 examples/s]Applying formatting function to eval dataset:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 5188/5960 [00:01<00:00, 2830.46 examples/s]Applying formatting function to eval dataset:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 5578/5960 [00:01<00:00, 3077.32 examples/s]Applying formatting function to eval dataset: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5960/5960 [00:02<00:00, 2849.27 examples/s]Applying formatting function to eval dataset: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5960/5960 [00:02<00:00, 2778.36 examples/s]
Adding EOS to eval dataset:   0%|          | 0/5960 [00:00<?, ? examples/s]Adding EOS to eval dataset:   8%|â–Š         | 506/5960 [00:00<00:01, 4983.00 examples/s]Adding EOS to eval dataset:  21%|â–ˆâ–ˆ        | 1255/5960 [00:00<00:01, 4410.75 examples/s]Adding EOS to eval dataset:  30%|â–ˆâ–ˆâ–‰       | 1766/5960 [00:00<00:00, 4662.27 examples/s]Adding EOS to eval dataset:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 2252/5960 [00:00<00:00, 4238.52 examples/s]Adding EOS to eval dataset:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2767/5960 [00:00<00:00, 4514.41 examples/s]Adding EOS to eval dataset:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3255/5960 [00:00<00:00, 4267.74 examples/s]Adding EOS to eval dataset:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3768/5960 [00:00<00:00, 4513.02 examples/s]Adding EOS to eval dataset:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4255/5960 [00:00<00:00, 4031.44 examples/s]Adding EOS to eval dataset:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4768/5960 [00:01<00:00, 4321.02 examples/s]Adding EOS to eval dataset:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 5257/5960 [00:01<00:00, 4175.11 examples/s]Adding EOS to eval dataset:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 5780/5960 [00:01<00:00, 4456.25 examples/s]Adding EOS to eval dataset: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5960/5960 [00:01<00:00, 4289.75 examples/s]
Tokenizing eval dataset:   0%|          | 0/5960 [00:00<?, ? examples/s]Tokenizing eval dataset:   1%|          | 43/5960 [00:00<00:14, 413.93 examples/s]Tokenizing eval dataset:   2%|â–         | 93/5960 [00:00<00:12, 458.52 examples/s]Tokenizing eval dataset:   2%|â–         | 142/5960 [00:00<00:12, 468.08 examples/s]Tokenizing eval dataset:   3%|â–Ž         | 191/5960 [00:00<00:12, 473.75 examples/s]Tokenizing eval dataset:   4%|â–         | 239/5960 [00:00<00:12, 470.86 examples/s]Tokenizing eval dataset:   5%|â–         | 289/5960 [00:00<00:11, 478.96 examples/s]Tokenizing eval dataset:   6%|â–Œ         | 337/5960 [00:00<00:11, 475.01 examples/s]Tokenizing eval dataset:   7%|â–‹         | 388/5960 [00:00<00:11, 481.02 examples/s]Tokenizing eval dataset:   7%|â–‹         | 438/5960 [00:00<00:11, 485.48 examples/s]Tokenizing eval dataset:   8%|â–Š         | 490/5960 [00:01<00:11, 492.22 examples/s]Tokenizing eval dataset:   9%|â–‰         | 541/5960 [00:01<00:10, 494.59 examples/s]Tokenizing eval dataset:  10%|â–ˆ         | 613/5960 [00:01<00:11, 485.15 examples/s]Tokenizing eval dataset:  11%|â–ˆ         | 662/5960 [00:01<00:10, 483.61 examples/s]Tokenizing eval dataset:  12%|â–ˆâ–        | 713/5960 [00:01<00:10, 487.47 examples/s]Tokenizing eval dataset:  13%|â–ˆâ–Ž        | 767/5960 [00:01<00:10, 497.24 examples/s]Tokenizing eval dataset:  14%|â–ˆâ–Ž        | 817/5960 [00:01<00:10, 494.79 examples/s]Tokenizing eval dataset:  15%|â–ˆâ–        | 892/5960 [00:01<00:10, 495.77 examples/s]Tokenizing eval dataset:  16%|â–ˆâ–Œ        | 944/5960 [00:01<00:10, 498.31 examples/s]Tokenizing eval dataset:  17%|â–ˆâ–‹        | 1000/5960 [00:02<00:20, 238.16 examples/s]Tokenizing eval dataset:  18%|â–ˆâ–Š        | 1048/5960 [00:02<00:17, 273.67 examples/s]Tokenizing eval dataset:  18%|â–ˆâ–Š        | 1096/5960 [00:02<00:15, 309.38 examples/s]Tokenizing eval dataset:  19%|â–ˆâ–‰        | 1145/5960 [00:02<00:14, 343.37 examples/s]Tokenizing eval dataset:  20%|â–ˆâ–ˆ        | 1193/5960 [00:02<00:12, 373.22 examples/s]Tokenizing eval dataset:  21%|â–ˆâ–ˆ        | 1241/5960 [00:02<00:11, 397.47 examples/s]Tokenizing eval dataset:  22%|â–ˆâ–ˆâ–       | 1290/5960 [00:03<00:11, 417.17 examples/s]Tokenizing eval dataset:  22%|â–ˆâ–ˆâ–Ž       | 1341/5960 [00:03<00:10, 440.04 examples/s]Tokenizing eval dataset:  23%|â–ˆâ–ˆâ–Ž       | 1391/5960 [00:03<00:10, 451.28 examples/s]Tokenizing eval dataset:  24%|â–ˆâ–ˆâ–       | 1442/5960 [00:03<00:09, 464.77 examples/s]Tokenizing eval dataset:  25%|â–ˆâ–ˆâ–Œ       | 1492/5960 [00:03<00:09, 473.20 examples/s]Tokenizing eval dataset:  26%|â–ˆâ–ˆâ–Œ       | 1544/5960 [00:03<00:09, 481.77 examples/s]Tokenizing eval dataset:  27%|â–ˆâ–ˆâ–‹       | 1617/5960 [00:03<00:09, 477.16 examples/s]Tokenizing eval dataset:  28%|â–ˆâ–ˆâ–Š       | 1667/5960 [00:03<00:08, 479.91 examples/s]Tokenizing eval dataset:  29%|â–ˆâ–ˆâ–‰       | 1720/5960 [00:03<00:08, 490.99 examples/s]Tokenizing eval dataset:  30%|â–ˆâ–ˆâ–ˆ       | 1791/5960 [00:04<00:08, 482.64 examples/s]Tokenizing eval dataset:  31%|â–ˆâ–ˆâ–ˆâ–      | 1866/5960 [00:04<00:08, 486.61 examples/s]Tokenizing eval dataset:  32%|â–ˆâ–ˆâ–ˆâ–      | 1916/5960 [00:04<00:08, 488.85 examples/s]Tokenizing eval dataset:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1971/5960 [00:04<00:07, 501.65 examples/s]Tokenizing eval dataset:  34%|â–ˆâ–ˆâ–ˆâ–      | 2043/5960 [00:04<00:11, 328.93 examples/s]Tokenizing eval dataset:  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 2091/5960 [00:04<00:10, 356.07 examples/s]Tokenizing eval dataset:  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 2140/5960 [00:05<00:09, 383.46 examples/s]Tokenizing eval dataset:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 2185/5960 [00:05<00:09, 396.49 examples/s]Tokenizing eval dataset:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 2233/5960 [00:05<00:09, 413.97 examples/s]Tokenizing eval dataset:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 2279/5960 [00:05<00:08, 424.99 examples/s]Tokenizing eval dataset:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 2330/5960 [00:05<00:08, 445.42 examples/s]Tokenizing eval dataset:  40%|â–ˆâ–ˆâ–ˆâ–‰      | 2379/5960 [00:05<00:07, 456.41 examples/s]Tokenizing eval dataset:  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2432/5960 [00:05<00:07, 476.53 examples/s]Tokenizing eval dataset:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2481/5960 [00:05<00:07, 477.40 examples/s]Tokenizing eval dataset:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2532/5960 [00:05<00:07, 483.08 examples/s]Tokenizing eval dataset:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 2604/5960 [00:05<00:07, 477.41 examples/s]Tokenizing eval dataset:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 2654/5960 [00:06<00:06, 479.25 examples/s]Tokenizing eval dataset:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2705/5960 [00:06<00:06, 485.86 examples/s]Tokenizing eval dataset:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 2755/5960 [00:06<00:06, 488.06 examples/s]Tokenizing eval dataset:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 2806/5960 [00:06<00:06, 488.78 examples/s]Tokenizing eval dataset:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 2877/5960 [00:06<00:06, 480.85 examples/s]Tokenizing eval dataset:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 2930/5960 [00:06<00:06, 490.70 examples/s]Tokenizing eval dataset:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3000/5960 [00:07<00:09, 320.54 examples/s]Tokenizing eval dataset:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3047/5960 [00:07<00:08, 347.16 examples/s]Tokenizing eval dataset:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3095/5960 [00:07<00:07, 373.86 examples/s]Tokenizing eval dataset:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3145/5960 [00:07<00:07, 401.40 examples/s]Tokenizing eval dataset:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 3195/5960 [00:07<00:06, 421.94 examples/s]Tokenizing eval dataset:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 3245/5960 [00:07<00:06, 441.04 examples/s]Tokenizing eval dataset:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3295/5960 [00:07<00:05, 453.89 examples/s]Tokenizing eval dataset:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 3347/5960 [00:07<00:05, 466.87 examples/s]Tokenizing eval dataset:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 3417/5960 [00:07<00:05, 463.64 examples/s]Tokenizing eval dataset:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 3466/5960 [00:07<00:05, 467.43 examples/s]Tokenizing eval dataset:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3518/5960 [00:08<00:05, 478.67 examples/s]Tokenizing eval dataset:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 3568/5960 [00:08<00:05, 478.38 examples/s]Tokenizing eval dataset:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3619/5960 [00:08<00:04, 483.78 examples/s]Tokenizing eval dataset:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3671/5960 [00:08<00:04, 491.61 examples/s]Tokenizing eval dataset:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3722/5960 [00:08<00:04, 493.99 examples/s]Tokenizing eval dataset:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 3797/5960 [00:08<00:04, 493.55 examples/s]Tokenizing eval dataset:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 3849/5960 [00:08<00:04, 496.97 examples/s]Tokenizing eval dataset:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 3902/5960 [00:08<00:04, 502.21 examples/s]Tokenizing eval dataset:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 3954/5960 [00:08<00:03, 503.15 examples/s]Tokenizing eval dataset:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4023/5960 [00:09<00:05, 335.57 examples/s]Tokenizing eval dataset:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 4071/5960 [00:09<00:05, 362.48 examples/s]Tokenizing eval dataset:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4122/5960 [00:09<00:04, 393.50 examples/s]Tokenizing eval dataset:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 4171/5960 [00:09<00:04, 413.98 examples/s]Tokenizing eval dataset:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 4220/5960 [00:09<00:04, 430.64 examples/s]Tokenizing eval dataset:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4269/5960 [00:09<00:03, 445.01 examples/s]Tokenizing eval dataset:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4318/5960 [00:09<00:03, 456.17 examples/s]Tokenizing eval dataset:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 4369/5960 [00:10<00:03, 469.40 examples/s]Tokenizing eval dataset:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 4420/5960 [00:10<00:03, 478.67 examples/s]Tokenizing eval dataset:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4470/5960 [00:10<00:03, 481.87 examples/s]Tokenizing eval dataset:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 4522/5960 [00:10<00:02, 490.32 examples/s]Tokenizing eval dataset:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 4573/5960 [00:10<00:02, 493.88 examples/s]Tokenizing eval dataset:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4625/5960 [00:10<00:02, 493.25 examples/s]Tokenizing eval dataset:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 4676/5960 [00:10<00:02, 494.78 examples/s]Tokenizing eval dataset:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 4728/5960 [00:10<00:02, 496.69 examples/s]Tokenizing eval dataset:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4780/5960 [00:10<00:02, 499.85 examples/s]Tokenizing eval dataset:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4856/5960 [00:10<00:02, 497.02 examples/s]Tokenizing eval dataset:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4908/5960 [00:11<00:02, 502.03 examples/s]Tokenizing eval dataset:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 4981/5960 [00:11<00:01, 492.51 examples/s]Tokenizing eval dataset:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 5048/5960 [00:11<00:02, 318.54 examples/s]Tokenizing eval dataset:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 5095/5960 [00:11<00:02, 343.30 examples/s]Tokenizing eval dataset:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 5142/5960 [00:11<00:02, 367.45 examples/s]Tokenizing eval dataset:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 5191/5960 [00:11<00:01, 391.55 examples/s]Tokenizing eval dataset:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 5240/5960 [00:12<00:01, 412.40 examples/s]Tokenizing eval dataset:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 5288/5960 [00:12<00:01, 426.50 examples/s]Tokenizing eval dataset:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 5338/5960 [00:12<00:01, 443.31 examples/s]Tokenizing eval dataset:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 5388/5960 [00:12<00:01, 457.19 examples/s]Tokenizing eval dataset:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 5438/5960 [00:12<00:01, 467.14 examples/s]Tokenizing eval dataset:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 5488/5960 [00:12<00:01, 471.95 examples/s]Tokenizing eval dataset:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 5539/5960 [00:12<00:00, 478.26 examples/s]Tokenizing eval dataset:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 5589/5960 [00:12<00:00, 482.18 examples/s]Tokenizing eval dataset:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 5663/5960 [00:12<00:00, 481.46 examples/s]Tokenizing eval dataset:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 5712/5960 [00:12<00:00, 482.59 examples/s]Tokenizing eval dataset:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 5785/5960 [00:13<00:00, 481.46 examples/s]Tokenizing eval dataset:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 5836/5960 [00:13<00:00, 486.18 examples/s]Tokenizing eval dataset:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 5888/5960 [00:13<00:00, 492.01 examples/s]Tokenizing eval dataset: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 5941/5960 [00:13<00:00, 498.71 examples/s]Tokenizing eval dataset: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5960/5960 [00:13<00:00, 435.84 examples/s]
Truncating eval dataset:   0%|          | 0/5960 [00:00<?, ? examples/s]Truncating eval dataset: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5960/5960 [00:00<00:00, 52452.89 examples/s]Truncating eval dataset: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5960/5960 [00:00<00:00, 50437.33 examples/s]
The tokenizer has new PAD/BOS/EOS tokens that differ from the model config and generation config. The model config and generation config were aligned accordingly, being updated with the tokenizer's values. Updated tokens: {'eos_token_id': 128009, 'pad_token_id': 128002}.
No checkpoint found. Starting training from scratch...
  0%|          | 0/2235 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
/home/ubuntu/Part-II-Project/venv/lib/python3.12/site-packages/torch/_dynamo/eval_frame.py:632: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.
  return fn(*args, **kwargs)
  0%|          | 1/2235 [00:24<15:13:57, 24.55s/it]  0%|          | 2/2235 [00:47<14:39:01, 23.62s/it]  0%|          | 3/2235 [01:10<14:36:15, 23.56s/it]  0%|          | 4/2235 [01:34<14:32:23, 23.46s/it]  0%|          | 5/2235 [01:57<14:27:15, 23.33s/it]  0%|          | 6/2235 [02:21<14:29:57, 23.42s/it]  0%|          | 7/2235 [02:43<14:15:06, 23.03s/it]  0%|          | 8/2235 [03:06<14:18:48, 23.14s/it]  0%|          | 9/2235 [03:29<14:18:40, 23.14s/it]  0%|          | 10/2235 [03:53<14:23:37, 23.29s/it]                                                      0%|          | 10/2235 [03:53<14:23:37, 23.29s/it]  0%|          | 11/2235 [04:16<14:24:34, 23.32s/it]  1%|          | 12/2235 [04:40<14:30:09, 23.49s/it]  1%|          | 13/2235 [05:04<14:28:57, 23.46s/it]  1%|          | 14/2235 [05:27<14:28:03, 23.45s/it]  1%|          | 15/2235 [05:51<14:29:50, 23.51s/it]  1%|          | 16/2235 [06:14<14:28:29, 23.48s/it]  1%|          | 17/2235 [06:37<14:25:02, 23.40s/it]  1%|          | 18/2235 [07:00<14:22:27, 23.34s/it]  1%|          | 19/2235 [07:24<14:25:36, 23.44s/it]  1%|          | 20/2235 [07:48<14:25:08, 23.44s/it]                                                      1%|          | 20/2235 [07:48<14:25:08, 23.44s/it]  1%|          | 21/2235 [08:11<14:27:09, 23.50s/it]  1%|          | 22/2235 [08:34<14:20:57, 23.34s/it]  1%|          | 23/2235 [08:57<14:16:28, 23.23s/it]  1%|          | 24/2235 [09:20<14:13:20, 23.16s/it]  1%|          | 25/2235 [09:43<14:10:54, 23.10s/it]  1%|          | 26/2235 [10:06<14:11:36, 23.13s/it]  1%|          | 27/2235 [10:29<14:12:00, 23.15s/it]  1%|â–         | 28/2235 [10:53<14:12:08, 23.17s/it]  1%|â–         | 29/2235 [11:17<14:19:36, 23.38s/it]  1%|â–         | 30/2235 [11:40<14:17:11, 23.32s/it]                                                      1%|â–         | 30/2235 [11:40<14:17:11, 23.32s/it]  1%|â–         | 31/2235 [12:03<14:17:56, 23.36s/it]